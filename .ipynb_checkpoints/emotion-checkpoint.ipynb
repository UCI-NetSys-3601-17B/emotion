{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import data_loader\n",
    "import numpy as np\n",
    "import keras\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images size is:  11086\n",
      "valid_images size is:  1226\n",
      "test_images size is:  1378\n",
      "label_dict size is:  8\n",
      "dict_keys(['disgust', 'fear', 'anger', 'sadness', 'contempt', 'neutral', 'surprise', 'happiness'])\n"
     ]
    }
   ],
   "source": [
    "img_dir_path = 'origin/images'\n",
    "label_file_path = 'origin/data/legend.csv'\n",
    "valid_rate = 0.1\n",
    "\n",
    "train_file_paths, \\\n",
    "train_labels, \\\n",
    "valid_file_paths, \\\n",
    "valid_labels, \\\n",
    "test_file_paths, \\\n",
    "test_labels, \\\n",
    "label_dict = data_loader.load_dataset(img_dir_path, label_file_path, valid_rate)\n",
    "\n",
    "print('train_images size is: ', len(train_file_paths))\n",
    "print('valid_images size is: ', len(valid_file_paths))\n",
    "print('test_images size is: ', len(test_file_paths))\n",
    "print('label_dict size is: ', len(label_dict))\n",
    "print(label_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170, 11, 206, 218, 0, 5565, 299, 4617]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 1, 22, 24, 0, 617, 33, 511]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 9, 24, 26, 9, 686, 36, 568]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def count_nums(labels, types):\n",
    "    count = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    for label in labels:\n",
    "        count[label] += 1\n",
    "    print(count)\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(range(len(count)), count, alpha=0.7) \n",
    "    plt.title(types + \" labels\") \n",
    "    plt.show()\n",
    "    \n",
    "count_nums(train_labels, \"train\")\n",
    "count_nums(valid_labels, \"valid\")\n",
    "count_nums(test_labels, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the extracted features by CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train is (11086, 512)\n",
      "x_valid is (1226, 512)\n",
      "x_test is (1378, 512)\n",
      "y_train is (11086, 8)\n",
      "y_valid is (1226, 8)\n",
      "y_test is (1378, 8)\n"
     ]
    }
   ],
   "source": [
    "with open(\"extract/x_train_norm\", \"rb\") as f:\n",
    "    x_train = np.array(pickle.load(f))\n",
    "\n",
    "with open(\"extract/x_valid_norm\", \"rb\") as f:\n",
    "    x_valid = np.array(pickle.load(f))\n",
    "\n",
    "with open(\"extract/x_test_norm\", \"rb\") as f:\n",
    "    x_test = np.array(pickle.load(f))\n",
    "\n",
    "y_train = np_utils.to_categorical(train_labels, 8)\n",
    "y_valid = np_utils.to_categorical(valid_labels, 8)\n",
    "y_test = np_utils.to_categorical(test_labels, 8)\n",
    "\n",
    "print(\"x_train is\", x_train.shape)\n",
    "print(\"x_valid is\", x_valid.shape)\n",
    "print(\"x_test is\", x_test.shape)\n",
    "\n",
    "print(\"y_train is\", y_train.shape)\n",
    "print(\"y_valid is\", y_valid.shape)\n",
    "print(\"y_test is\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11086 samples, validate on 1226 samples\n",
      "Epoch 1/1000\n",
      "11086/11086 [==============================] - 1s 127us/step - loss: 0.4372 - acc: 0.7961 - val_loss: 0.2349 - val_acc: 0.8654\n",
      "Epoch 2/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.3084 - acc: 0.8512 - val_loss: 0.2218 - val_acc: 0.8756\n",
      "Epoch 3/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2698 - acc: 0.8645 - val_loss: 0.2217 - val_acc: 0.8758\n",
      "Epoch 4/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2566 - acc: 0.8700 - val_loss: 0.2216 - val_acc: 0.8723\n",
      "Epoch 5/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2480 - acc: 0.8721 - val_loss: 0.2219 - val_acc: 0.8758\n",
      "Epoch 6/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2450 - acc: 0.8740 - val_loss: 0.2232 - val_acc: 0.8758\n",
      "Epoch 7/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.2420 - acc: 0.8735 - val_loss: 0.2217 - val_acc: 0.8747\n",
      "Epoch 8/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2398 - acc: 0.8733 - val_loss: 0.2218 - val_acc: 0.8738\n",
      "Epoch 9/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2390 - acc: 0.8750 - val_loss: 0.2209 - val_acc: 0.8761\n",
      "Epoch 10/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2378 - acc: 0.8746 - val_loss: 0.2211 - val_acc: 0.8750\n",
      "Epoch 11/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2367 - acc: 0.8749 - val_loss: 0.2221 - val_acc: 0.8750\n",
      "Epoch 12/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2353 - acc: 0.8753 - val_loss: 0.2229 - val_acc: 0.8758\n",
      "Epoch 13/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2352 - acc: 0.8755 - val_loss: 0.2217 - val_acc: 0.8758\n",
      "Epoch 14/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2346 - acc: 0.8757 - val_loss: 0.2236 - val_acc: 0.8758\n",
      "Epoch 15/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2345 - acc: 0.8756 - val_loss: 0.2217 - val_acc: 0.8750\n",
      "Epoch 16/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2337 - acc: 0.8759 - val_loss: 0.2211 - val_acc: 0.8750\n",
      "Epoch 17/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2337 - acc: 0.8743 - val_loss: 0.2211 - val_acc: 0.8750\n",
      "Epoch 18/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2328 - acc: 0.8748 - val_loss: 0.2221 - val_acc: 0.8758\n",
      "Epoch 19/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2329 - acc: 0.8759 - val_loss: 0.2216 - val_acc: 0.8750\n",
      "Epoch 20/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2327 - acc: 0.8759 - val_loss: 0.2212 - val_acc: 0.8750\n",
      "Epoch 21/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2320 - acc: 0.8751 - val_loss: 0.2214 - val_acc: 0.8758\n",
      "Epoch 22/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2315 - acc: 0.8752 - val_loss: 0.2219 - val_acc: 0.8750\n",
      "Epoch 23/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2312 - acc: 0.8761 - val_loss: 0.2220 - val_acc: 0.8750\n",
      "Epoch 24/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2316 - acc: 0.8757 - val_loss: 0.2214 - val_acc: 0.8750\n",
      "Epoch 25/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2305 - acc: 0.8754 - val_loss: 0.2216 - val_acc: 0.8761\n",
      "Epoch 26/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2300 - acc: 0.8751 - val_loss: 0.2211 - val_acc: 0.8758\n",
      "Epoch 27/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2302 - acc: 0.8757 - val_loss: 0.2221 - val_acc: 0.8822\n",
      "Epoch 28/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2299 - acc: 0.8745 - val_loss: 0.2216 - val_acc: 0.8753\n",
      "Epoch 29/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2290 - acc: 0.8760 - val_loss: 0.2220 - val_acc: 0.8784\n",
      "Epoch 30/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2282 - acc: 0.8763 - val_loss: 0.2220 - val_acc: 0.8744\n",
      "Epoch 31/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2287 - acc: 0.8758 - val_loss: 0.2220 - val_acc: 0.8758\n",
      "Epoch 32/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2285 - acc: 0.8758 - val_loss: 0.2223 - val_acc: 0.8758\n",
      "Epoch 33/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2274 - acc: 0.8747 - val_loss: 0.2222 - val_acc: 0.8758\n",
      "Epoch 34/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2276 - acc: 0.8761 - val_loss: 0.2218 - val_acc: 0.8768\n",
      "Epoch 35/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2278 - acc: 0.8765 - val_loss: 0.2218 - val_acc: 0.8765\n",
      "Epoch 36/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2279 - acc: 0.8766 - val_loss: 0.2222 - val_acc: 0.8758\n",
      "Epoch 37/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2272 - acc: 0.8757 - val_loss: 0.2228 - val_acc: 0.8761\n",
      "Epoch 38/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2274 - acc: 0.8756 - val_loss: 0.2228 - val_acc: 0.8764\n",
      "Epoch 39/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2271 - acc: 0.8747 - val_loss: 0.2217 - val_acc: 0.8762\n",
      "Epoch 40/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2266 - acc: 0.8758 - val_loss: 0.2223 - val_acc: 0.8758\n",
      "Epoch 41/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2266 - acc: 0.8755 - val_loss: 0.2217 - val_acc: 0.8775\n",
      "Epoch 42/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2263 - acc: 0.8754 - val_loss: 0.2220 - val_acc: 0.8769\n",
      "Epoch 43/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2255 - acc: 0.8753 - val_loss: 0.2221 - val_acc: 0.8770\n",
      "Epoch 44/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2253 - acc: 0.8763 - val_loss: 0.2224 - val_acc: 0.8779\n",
      "Epoch 45/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2261 - acc: 0.8764 - val_loss: 0.2223 - val_acc: 0.8762\n",
      "Epoch 46/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2255 - acc: 0.8756 - val_loss: 0.2223 - val_acc: 0.8743\n",
      "Epoch 47/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2258 - acc: 0.8761 - val_loss: 0.2227 - val_acc: 0.8714\n",
      "Epoch 48/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2246 - acc: 0.8765 - val_loss: 0.2226 - val_acc: 0.8720\n",
      "Epoch 49/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2253 - acc: 0.8762 - val_loss: 0.2224 - val_acc: 0.8717\n",
      "Epoch 50/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2251 - acc: 0.8764 - val_loss: 0.2222 - val_acc: 0.8778\n",
      "Epoch 51/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2240 - acc: 0.8763 - val_loss: 0.2224 - val_acc: 0.8745\n",
      "Epoch 52/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2244 - acc: 0.8759 - val_loss: 0.2224 - val_acc: 0.8775\n",
      "Epoch 53/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2240 - acc: 0.8767 - val_loss: 0.2225 - val_acc: 0.8735\n",
      "Epoch 54/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2239 - acc: 0.8766 - val_loss: 0.2228 - val_acc: 0.8766\n",
      "Epoch 55/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2241 - acc: 0.8770 - val_loss: 0.2229 - val_acc: 0.8743\n",
      "Epoch 56/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2235 - acc: 0.8767 - val_loss: 0.2229 - val_acc: 0.8739\n",
      "Epoch 57/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2237 - acc: 0.8774 - val_loss: 0.2234 - val_acc: 0.8754\n",
      "Epoch 58/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2236 - acc: 0.8757 - val_loss: 0.2229 - val_acc: 0.8758\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2226 - acc: 0.8767 - val_loss: 0.2230 - val_acc: 0.8763\n",
      "Epoch 60/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2235 - acc: 0.8774 - val_loss: 0.2230 - val_acc: 0.8734\n",
      "Epoch 61/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2229 - acc: 0.8774 - val_loss: 0.2229 - val_acc: 0.8769\n",
      "Epoch 62/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2231 - acc: 0.8774 - val_loss: 0.2232 - val_acc: 0.8761\n",
      "Epoch 63/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2229 - acc: 0.8763 - val_loss: 0.2227 - val_acc: 0.8751\n",
      "Epoch 64/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2229 - acc: 0.8776 - val_loss: 0.2234 - val_acc: 0.8741\n",
      "Epoch 65/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2226 - acc: 0.8767 - val_loss: 0.2241 - val_acc: 0.8768\n",
      "Epoch 66/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2226 - acc: 0.8769 - val_loss: 0.2235 - val_acc: 0.8732\n",
      "Epoch 67/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2223 - acc: 0.8780 - val_loss: 0.2236 - val_acc: 0.8768\n",
      "Epoch 68/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2220 - acc: 0.8785 - val_loss: 0.2231 - val_acc: 0.8780\n",
      "Epoch 69/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2226 - acc: 0.8774 - val_loss: 0.2232 - val_acc: 0.8777\n",
      "Epoch 70/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2222 - acc: 0.8776 - val_loss: 0.2234 - val_acc: 0.8749\n",
      "Epoch 71/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2218 - acc: 0.8793 - val_loss: 0.2247 - val_acc: 0.8738\n",
      "Epoch 72/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2219 - acc: 0.8765 - val_loss: 0.2241 - val_acc: 0.8775\n",
      "Epoch 73/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2218 - acc: 0.8775 - val_loss: 0.2244 - val_acc: 0.8751\n",
      "Epoch 74/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2213 - acc: 0.8774 - val_loss: 0.2236 - val_acc: 0.8766\n",
      "Epoch 75/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2217 - acc: 0.8775 - val_loss: 0.2233 - val_acc: 0.8771\n",
      "Epoch 76/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2214 - acc: 0.8777 - val_loss: 0.2243 - val_acc: 0.8749\n",
      "Epoch 77/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2213 - acc: 0.8780 - val_loss: 0.2233 - val_acc: 0.8767\n",
      "Epoch 78/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2214 - acc: 0.8791 - val_loss: 0.2240 - val_acc: 0.8759\n",
      "Epoch 79/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2211 - acc: 0.8776 - val_loss: 0.2243 - val_acc: 0.8786\n",
      "Epoch 80/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2212 - acc: 0.8774 - val_loss: 0.2251 - val_acc: 0.8736\n",
      "Epoch 81/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2210 - acc: 0.8773 - val_loss: 0.2245 - val_acc: 0.8765\n",
      "Epoch 82/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2207 - acc: 0.8776 - val_loss: 0.2247 - val_acc: 0.8788\n",
      "Epoch 83/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2208 - acc: 0.8778 - val_loss: 0.2237 - val_acc: 0.8764\n",
      "Epoch 84/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2210 - acc: 0.8786 - val_loss: 0.2249 - val_acc: 0.8756\n",
      "Epoch 85/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2209 - acc: 0.8776 - val_loss: 0.2245 - val_acc: 0.8766\n",
      "Epoch 86/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2207 - acc: 0.8781 - val_loss: 0.2263 - val_acc: 0.8762\n",
      "Epoch 87/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2206 - acc: 0.8788 - val_loss: 0.2245 - val_acc: 0.8751\n",
      "Epoch 88/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2207 - acc: 0.8791 - val_loss: 0.2252 - val_acc: 0.8751\n",
      "Epoch 89/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2205 - acc: 0.8784 - val_loss: 0.2260 - val_acc: 0.8738\n",
      "Epoch 90/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2204 - acc: 0.8778 - val_loss: 0.2244 - val_acc: 0.8745\n",
      "Epoch 91/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2199 - acc: 0.8792 - val_loss: 0.2257 - val_acc: 0.8760\n",
      "Epoch 92/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2200 - acc: 0.8789 - val_loss: 0.2256 - val_acc: 0.8746\n",
      "Epoch 93/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2203 - acc: 0.8791 - val_loss: 0.2258 - val_acc: 0.8739\n",
      "Epoch 94/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2200 - acc: 0.8802 - val_loss: 0.2259 - val_acc: 0.8741\n",
      "Epoch 95/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2201 - acc: 0.8794 - val_loss: 0.2263 - val_acc: 0.8750\n",
      "Epoch 96/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2204 - acc: 0.8788 - val_loss: 0.2249 - val_acc: 0.8757\n",
      "Epoch 97/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2200 - acc: 0.8793 - val_loss: 0.2258 - val_acc: 0.8744\n",
      "Epoch 98/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2202 - acc: 0.8781 - val_loss: 0.2261 - val_acc: 0.8744\n",
      "Epoch 99/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2197 - acc: 0.8797 - val_loss: 0.2263 - val_acc: 0.8730\n",
      "Epoch 100/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2199 - acc: 0.8792 - val_loss: 0.2262 - val_acc: 0.8742\n",
      "Epoch 101/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2193 - acc: 0.8809 - val_loss: 0.2264 - val_acc: 0.8767\n",
      "Epoch 102/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2197 - acc: 0.8789 - val_loss: 0.2274 - val_acc: 0.8749\n",
      "Epoch 103/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2196 - acc: 0.8800 - val_loss: 0.2263 - val_acc: 0.8744\n",
      "Epoch 104/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2198 - acc: 0.8794 - val_loss: 0.2273 - val_acc: 0.8763\n",
      "Epoch 105/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2191 - acc: 0.8800 - val_loss: 0.2270 - val_acc: 0.8742\n",
      "Epoch 106/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2185 - acc: 0.8799 - val_loss: 0.2271 - val_acc: 0.8750\n",
      "Epoch 107/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2192 - acc: 0.8795 - val_loss: 0.2272 - val_acc: 0.8762\n",
      "Epoch 108/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2192 - acc: 0.8786 - val_loss: 0.2272 - val_acc: 0.8756\n",
      "Epoch 109/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2189 - acc: 0.8790 - val_loss: 0.2273 - val_acc: 0.8743\n",
      "Epoch 110/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2191 - acc: 0.8799 - val_loss: 0.2275 - val_acc: 0.8743\n",
      "Epoch 111/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2191 - acc: 0.8796 - val_loss: 0.2266 - val_acc: 0.8742\n",
      "Epoch 112/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2187 - acc: 0.8800 - val_loss: 0.2270 - val_acc: 0.8737\n",
      "Epoch 113/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2184 - acc: 0.8801 - val_loss: 0.2256 - val_acc: 0.8761\n",
      "Epoch 114/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2186 - acc: 0.8803 - val_loss: 0.2268 - val_acc: 0.8725\n",
      "Epoch 115/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2186 - acc: 0.8794 - val_loss: 0.2270 - val_acc: 0.8738\n",
      "Epoch 116/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2185 - acc: 0.8805 - val_loss: 0.2262 - val_acc: 0.8774\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2188 - acc: 0.8798 - val_loss: 0.2270 - val_acc: 0.8748\n",
      "Epoch 118/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2184 - acc: 0.8799 - val_loss: 0.2284 - val_acc: 0.8752\n",
      "Epoch 119/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2185 - acc: 0.8807 - val_loss: 0.2269 - val_acc: 0.8752\n",
      "Epoch 120/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2184 - acc: 0.8804 - val_loss: 0.2270 - val_acc: 0.8741\n",
      "Epoch 121/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2182 - acc: 0.8806 - val_loss: 0.2269 - val_acc: 0.8767\n",
      "Epoch 122/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2178 - acc: 0.8809 - val_loss: 0.2291 - val_acc: 0.8770\n",
      "Epoch 123/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2181 - acc: 0.8803 - val_loss: 0.2285 - val_acc: 0.8754\n",
      "Epoch 124/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2182 - acc: 0.8799 - val_loss: 0.2268 - val_acc: 0.8761\n",
      "Epoch 125/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2176 - acc: 0.8814 - val_loss: 0.2295 - val_acc: 0.8737\n",
      "Epoch 126/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2172 - acc: 0.8804 - val_loss: 0.2272 - val_acc: 0.8769\n",
      "Epoch 127/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2174 - acc: 0.8806 - val_loss: 0.2275 - val_acc: 0.8763\n",
      "Epoch 128/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2175 - acc: 0.8812 - val_loss: 0.2276 - val_acc: 0.8741\n",
      "Epoch 129/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2175 - acc: 0.8815 - val_loss: 0.2268 - val_acc: 0.8751\n",
      "Epoch 130/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2178 - acc: 0.8806 - val_loss: 0.2290 - val_acc: 0.8751\n",
      "Epoch 131/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2174 - acc: 0.8812 - val_loss: 0.2277 - val_acc: 0.8764\n",
      "Epoch 132/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2173 - acc: 0.8807 - val_loss: 0.2288 - val_acc: 0.8755\n",
      "Epoch 133/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2172 - acc: 0.8817 - val_loss: 0.2295 - val_acc: 0.8731\n",
      "Epoch 134/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2170 - acc: 0.8811 - val_loss: 0.2286 - val_acc: 0.8723\n",
      "Epoch 135/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2172 - acc: 0.8816 - val_loss: 0.2277 - val_acc: 0.8762\n",
      "Epoch 136/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2166 - acc: 0.8819 - val_loss: 0.2287 - val_acc: 0.8752\n",
      "Epoch 137/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2164 - acc: 0.8820 - val_loss: 0.2308 - val_acc: 0.8727\n",
      "Epoch 138/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2166 - acc: 0.8816 - val_loss: 0.2301 - val_acc: 0.8779\n",
      "Epoch 139/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2160 - acc: 0.8823 - val_loss: 0.2291 - val_acc: 0.8789\n",
      "Epoch 140/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2166 - acc: 0.8818 - val_loss: 0.2287 - val_acc: 0.8745\n",
      "Epoch 141/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2158 - acc: 0.8820 - val_loss: 0.2297 - val_acc: 0.8740\n",
      "Epoch 142/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2158 - acc: 0.8824 - val_loss: 0.2304 - val_acc: 0.8754\n",
      "Epoch 143/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2161 - acc: 0.8820 - val_loss: 0.2294 - val_acc: 0.8748\n",
      "Epoch 144/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2154 - acc: 0.8831 - val_loss: 0.2296 - val_acc: 0.8778\n",
      "Epoch 145/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2158 - acc: 0.8826 - val_loss: 0.2293 - val_acc: 0.8772\n",
      "Epoch 146/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2154 - acc: 0.8828 - val_loss: 0.2335 - val_acc: 0.8765\n",
      "Epoch 147/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2151 - acc: 0.8837 - val_loss: 0.2313 - val_acc: 0.8748\n",
      "Epoch 148/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2153 - acc: 0.8830 - val_loss: 0.2303 - val_acc: 0.8762\n",
      "Epoch 149/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2156 - acc: 0.8839 - val_loss: 0.2308 - val_acc: 0.8765\n",
      "Epoch 150/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2156 - acc: 0.8834 - val_loss: 0.2306 - val_acc: 0.8764\n",
      "Epoch 151/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2148 - acc: 0.8832 - val_loss: 0.2283 - val_acc: 0.8771\n",
      "Epoch 152/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2152 - acc: 0.8831 - val_loss: 0.2275 - val_acc: 0.8754\n",
      "Epoch 153/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2152 - acc: 0.8833 - val_loss: 0.2299 - val_acc: 0.8748\n",
      "Epoch 154/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2140 - acc: 0.8839 - val_loss: 0.2321 - val_acc: 0.8755\n",
      "Epoch 155/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2143 - acc: 0.8831 - val_loss: 0.2331 - val_acc: 0.8741\n",
      "Epoch 156/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2137 - acc: 0.8849 - val_loss: 0.2319 - val_acc: 0.8761\n",
      "Epoch 157/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2144 - acc: 0.8842 - val_loss: 0.2328 - val_acc: 0.8767\n",
      "Epoch 158/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2142 - acc: 0.8844 - val_loss: 0.2306 - val_acc: 0.8780\n",
      "Epoch 159/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2142 - acc: 0.8842 - val_loss: 0.2347 - val_acc: 0.8745\n",
      "Epoch 160/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2139 - acc: 0.8854 - val_loss: 0.2302 - val_acc: 0.8751\n",
      "Epoch 161/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2137 - acc: 0.8839 - val_loss: 0.2293 - val_acc: 0.8728\n",
      "Epoch 162/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2131 - acc: 0.8855 - val_loss: 0.2327 - val_acc: 0.8754\n",
      "Epoch 163/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2136 - acc: 0.8839 - val_loss: 0.2337 - val_acc: 0.8768\n",
      "Epoch 164/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2130 - acc: 0.8851 - val_loss: 0.2344 - val_acc: 0.8738\n",
      "Epoch 165/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2135 - acc: 0.8847 - val_loss: 0.2338 - val_acc: 0.8750\n",
      "Epoch 166/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2129 - acc: 0.8854 - val_loss: 0.2316 - val_acc: 0.8754\n",
      "Epoch 167/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2122 - acc: 0.8860 - val_loss: 0.2330 - val_acc: 0.8764\n",
      "Epoch 168/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2117 - acc: 0.8855 - val_loss: 0.2321 - val_acc: 0.8772\n",
      "Epoch 169/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2118 - acc: 0.8864 - val_loss: 0.2341 - val_acc: 0.8749\n",
      "Epoch 170/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2119 - acc: 0.8865 - val_loss: 0.2336 - val_acc: 0.8763\n",
      "Epoch 171/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2116 - acc: 0.8858 - val_loss: 0.2326 - val_acc: 0.8752\n",
      "Epoch 172/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2118 - acc: 0.8862 - val_loss: 0.2334 - val_acc: 0.8756\n",
      "Epoch 173/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2112 - acc: 0.8860 - val_loss: 0.2362 - val_acc: 0.8745\n",
      "Epoch 174/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2114 - acc: 0.8861 - val_loss: 0.2349 - val_acc: 0.8767\n",
      "Epoch 175/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2107 - acc: 0.8882 - val_loss: 0.2352 - val_acc: 0.8737\n",
      "Epoch 176/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2117 - acc: 0.8870 - val_loss: 0.2321 - val_acc: 0.8770\n",
      "Epoch 177/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2106 - acc: 0.8868 - val_loss: 0.2336 - val_acc: 0.8782\n",
      "Epoch 178/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2106 - acc: 0.8875 - val_loss: 0.2338 - val_acc: 0.8761\n",
      "Epoch 179/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2100 - acc: 0.8874 - val_loss: 0.2362 - val_acc: 0.8749\n",
      "Epoch 180/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2102 - acc: 0.8884 - val_loss: 0.2387 - val_acc: 0.8761\n",
      "Epoch 181/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2104 - acc: 0.8879 - val_loss: 0.2398 - val_acc: 0.8728\n",
      "Epoch 182/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2095 - acc: 0.8887 - val_loss: 0.2369 - val_acc: 0.8758\n",
      "Epoch 183/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2093 - acc: 0.8875 - val_loss: 0.2362 - val_acc: 0.8755\n",
      "Epoch 184/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2094 - acc: 0.8875 - val_loss: 0.2369 - val_acc: 0.8755\n",
      "Epoch 185/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2090 - acc: 0.8883 - val_loss: 0.2389 - val_acc: 0.8758\n",
      "Epoch 186/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2087 - acc: 0.8882 - val_loss: 0.2414 - val_acc: 0.8750\n",
      "Epoch 187/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2084 - acc: 0.8887 - val_loss: 0.2391 - val_acc: 0.8762\n",
      "Epoch 188/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2087 - acc: 0.8885 - val_loss: 0.2365 - val_acc: 0.8760\n",
      "Epoch 189/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2087 - acc: 0.8891 - val_loss: 0.2372 - val_acc: 0.8753\n",
      "Epoch 190/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2082 - acc: 0.8887 - val_loss: 0.2401 - val_acc: 0.8744\n",
      "Epoch 191/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2069 - acc: 0.8891 - val_loss: 0.2404 - val_acc: 0.8751\n",
      "Epoch 192/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2068 - acc: 0.8896 - val_loss: 0.2392 - val_acc: 0.8755\n",
      "Epoch 193/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2072 - acc: 0.8896 - val_loss: 0.2419 - val_acc: 0.8722\n",
      "Epoch 194/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2068 - acc: 0.8907 - val_loss: 0.2419 - val_acc: 0.8744\n",
      "Epoch 195/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2073 - acc: 0.8894 - val_loss: 0.2394 - val_acc: 0.8765\n",
      "Epoch 196/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2071 - acc: 0.8903 - val_loss: 0.2421 - val_acc: 0.8730\n",
      "Epoch 197/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2068 - acc: 0.8896 - val_loss: 0.2399 - val_acc: 0.8731\n",
      "Epoch 198/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2066 - acc: 0.8906 - val_loss: 0.2428 - val_acc: 0.8758\n",
      "Epoch 199/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2062 - acc: 0.8907 - val_loss: 0.2429 - val_acc: 0.8748\n",
      "Epoch 200/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2054 - acc: 0.8908 - val_loss: 0.2401 - val_acc: 0.8779\n",
      "Epoch 201/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2045 - acc: 0.8914 - val_loss: 0.2503 - val_acc: 0.8745\n",
      "Epoch 202/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2057 - acc: 0.8907 - val_loss: 0.2481 - val_acc: 0.8732\n",
      "Epoch 203/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2057 - acc: 0.8902 - val_loss: 0.2458 - val_acc: 0.8750\n",
      "Epoch 204/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.2050 - acc: 0.8912 - val_loss: 0.2477 - val_acc: 0.8762\n",
      "Epoch 205/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2046 - acc: 0.8917 - val_loss: 0.2460 - val_acc: 0.8759\n",
      "Epoch 206/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2043 - acc: 0.8918 - val_loss: 0.2472 - val_acc: 0.8748\n",
      "Epoch 207/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2039 - acc: 0.8919 - val_loss: 0.2505 - val_acc: 0.8737\n",
      "Epoch 208/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2049 - acc: 0.8922 - val_loss: 0.2484 - val_acc: 0.8747\n",
      "Epoch 209/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2028 - acc: 0.8928 - val_loss: 0.2465 - val_acc: 0.8747\n",
      "Epoch 210/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2031 - acc: 0.8937 - val_loss: 0.2459 - val_acc: 0.8726\n",
      "Epoch 211/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2040 - acc: 0.8919 - val_loss: 0.2496 - val_acc: 0.8723\n",
      "Epoch 212/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2028 - acc: 0.8935 - val_loss: 0.2465 - val_acc: 0.8743\n",
      "Epoch 213/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2032 - acc: 0.8928 - val_loss: 0.2483 - val_acc: 0.8739\n",
      "Epoch 214/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2035 - acc: 0.8935 - val_loss: 0.2493 - val_acc: 0.8743\n",
      "Epoch 215/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2027 - acc: 0.8934 - val_loss: 0.2509 - val_acc: 0.8714\n",
      "Epoch 216/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2022 - acc: 0.8942 - val_loss: 0.2547 - val_acc: 0.8746\n",
      "Epoch 217/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2014 - acc: 0.8931 - val_loss: 0.2512 - val_acc: 0.8747\n",
      "Epoch 218/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2017 - acc: 0.8940 - val_loss: 0.2522 - val_acc: 0.8746\n",
      "Epoch 219/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2012 - acc: 0.8949 - val_loss: 0.2553 - val_acc: 0.8733\n",
      "Epoch 220/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2006 - acc: 0.8954 - val_loss: 0.2572 - val_acc: 0.8746\n",
      "Epoch 221/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2010 - acc: 0.8945 - val_loss: 0.2530 - val_acc: 0.8758\n",
      "Epoch 222/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2006 - acc: 0.8946 - val_loss: 0.2515 - val_acc: 0.8740\n",
      "Epoch 223/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2007 - acc: 0.8958 - val_loss: 0.2580 - val_acc: 0.8720\n",
      "Epoch 224/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1992 - acc: 0.8958 - val_loss: 0.2578 - val_acc: 0.8746\n",
      "Epoch 225/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1997 - acc: 0.8960 - val_loss: 0.2568 - val_acc: 0.8733\n",
      "Epoch 226/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1990 - acc: 0.8972 - val_loss: 0.2596 - val_acc: 0.8703\n",
      "Epoch 227/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.2000 - acc: 0.8958 - val_loss: 0.2545 - val_acc: 0.8702\n",
      "Epoch 228/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2002 - acc: 0.8963 - val_loss: 0.2565 - val_acc: 0.8758\n",
      "Epoch 229/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.2000 - acc: 0.8964 - val_loss: 0.2589 - val_acc: 0.8729\n",
      "Epoch 230/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1999 - acc: 0.8948 - val_loss: 0.2586 - val_acc: 0.8730\n",
      "Epoch 231/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1991 - acc: 0.8970 - val_loss: 0.2560 - val_acc: 0.8756\n",
      "Epoch 232/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1985 - acc: 0.8963 - val_loss: 0.2620 - val_acc: 0.8721\n",
      "Epoch 233/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1986 - acc: 0.8969 - val_loss: 0.2613 - val_acc: 0.8743\n",
      "Epoch 234/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1987 - acc: 0.8984 - val_loss: 0.2547 - val_acc: 0.8749\n",
      "Epoch 235/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1980 - acc: 0.8965 - val_loss: 0.2615 - val_acc: 0.8740\n",
      "Epoch 236/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1972 - acc: 0.8975 - val_loss: 0.2609 - val_acc: 0.8685\n",
      "Epoch 237/1000\n",
      "11086/11086 [==============================] - 0s 30us/step - loss: 0.1983 - acc: 0.8959 - val_loss: 0.2655 - val_acc: 0.8705\n",
      "Epoch 238/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1961 - acc: 0.8983 - val_loss: 0.2618 - val_acc: 0.8726\n",
      "Epoch 239/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1966 - acc: 0.8980 - val_loss: 0.2644 - val_acc: 0.8732\n",
      "Epoch 240/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1967 - acc: 0.8982 - val_loss: 0.2641 - val_acc: 0.8745\n",
      "Epoch 241/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1963 - acc: 0.8980 - val_loss: 0.2621 - val_acc: 0.8737\n",
      "Epoch 242/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1952 - acc: 0.8987 - val_loss: 0.2643 - val_acc: 0.8725\n",
      "Epoch 243/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1945 - acc: 0.8994 - val_loss: 0.2728 - val_acc: 0.8690\n",
      "Epoch 244/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1955 - acc: 0.8984 - val_loss: 0.2685 - val_acc: 0.8739\n",
      "Epoch 245/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1971 - acc: 0.8985 - val_loss: 0.2638 - val_acc: 0.8753\n",
      "Epoch 246/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1956 - acc: 0.8978 - val_loss: 0.2680 - val_acc: 0.8726\n",
      "Epoch 247/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1951 - acc: 0.8986 - val_loss: 0.2634 - val_acc: 0.8736\n",
      "Epoch 248/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1944 - acc: 0.8990 - val_loss: 0.2693 - val_acc: 0.8717\n",
      "Epoch 249/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1950 - acc: 0.9003 - val_loss: 0.2658 - val_acc: 0.8722\n",
      "Epoch 250/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1959 - acc: 0.8988 - val_loss: 0.2734 - val_acc: 0.8732\n",
      "Epoch 251/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1936 - acc: 0.9003 - val_loss: 0.2711 - val_acc: 0.8709\n",
      "Epoch 252/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1950 - acc: 0.8989 - val_loss: 0.2647 - val_acc: 0.8703\n",
      "Epoch 253/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1931 - acc: 0.9010 - val_loss: 0.2640 - val_acc: 0.8726\n",
      "Epoch 254/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1934 - acc: 0.9002 - val_loss: 0.2679 - val_acc: 0.8757\n",
      "Epoch 255/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1946 - acc: 0.9006 - val_loss: 0.2709 - val_acc: 0.8680\n",
      "Epoch 256/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1937 - acc: 0.9009 - val_loss: 0.2636 - val_acc: 0.8695\n",
      "Epoch 257/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1926 - acc: 0.9013 - val_loss: 0.2803 - val_acc: 0.8665\n",
      "Epoch 258/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1925 - acc: 0.9017 - val_loss: 0.2746 - val_acc: 0.8696\n",
      "Epoch 259/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1909 - acc: 0.9022 - val_loss: 0.2697 - val_acc: 0.8690\n",
      "Epoch 260/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1902 - acc: 0.9034 - val_loss: 0.2782 - val_acc: 0.8668\n",
      "Epoch 261/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1913 - acc: 0.9022 - val_loss: 0.2876 - val_acc: 0.8688\n",
      "Epoch 262/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1901 - acc: 0.9037 - val_loss: 0.2788 - val_acc: 0.8667\n",
      "Epoch 263/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1905 - acc: 0.9015 - val_loss: 0.2747 - val_acc: 0.8720\n",
      "Epoch 264/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1914 - acc: 0.9019 - val_loss: 0.2760 - val_acc: 0.8708\n",
      "Epoch 265/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1898 - acc: 0.9039 - val_loss: 0.2721 - val_acc: 0.8662\n",
      "Epoch 266/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1902 - acc: 0.9023 - val_loss: 0.2845 - val_acc: 0.8684\n",
      "Epoch 267/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1887 - acc: 0.9036 - val_loss: 0.2834 - val_acc: 0.8704\n",
      "Epoch 268/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1895 - acc: 0.9045 - val_loss: 0.2812 - val_acc: 0.8701\n",
      "Epoch 269/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1898 - acc: 0.9031 - val_loss: 0.2854 - val_acc: 0.8704\n",
      "Epoch 270/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1898 - acc: 0.9035 - val_loss: 0.2849 - val_acc: 0.8685\n",
      "Epoch 271/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1898 - acc: 0.9032 - val_loss: 0.2751 - val_acc: 0.8682\n",
      "Epoch 272/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1896 - acc: 0.9028 - val_loss: 0.2841 - val_acc: 0.8698\n",
      "Epoch 273/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1875 - acc: 0.9053 - val_loss: 0.2839 - val_acc: 0.8697\n",
      "Epoch 274/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1893 - acc: 0.9048 - val_loss: 0.2818 - val_acc: 0.8669\n",
      "Epoch 275/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1887 - acc: 0.9052 - val_loss: 0.2866 - val_acc: 0.8658\n",
      "Epoch 276/1000\n",
      "11086/11086 [==============================] - 0s 32us/step - loss: 0.1882 - acc: 0.9035 - val_loss: 0.2859 - val_acc: 0.8708\n",
      "Epoch 277/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1871 - acc: 0.9061 - val_loss: 0.2799 - val_acc: 0.8686\n",
      "Epoch 278/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1865 - acc: 0.9052 - val_loss: 0.2940 - val_acc: 0.8686\n",
      "Epoch 279/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1874 - acc: 0.9056 - val_loss: 0.2854 - val_acc: 0.8680\n",
      "Epoch 280/1000\n",
      "11086/11086 [==============================] - 0s 30us/step - loss: 0.1846 - acc: 0.9078 - val_loss: 0.2956 - val_acc: 0.8619\n",
      "Epoch 281/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1844 - acc: 0.9065 - val_loss: 0.2885 - val_acc: 0.8659\n",
      "Epoch 282/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1865 - acc: 0.9053 - val_loss: 0.2996 - val_acc: 0.8677\n",
      "Epoch 283/1000\n",
      "11086/11086 [==============================] - 0s 30us/step - loss: 0.1860 - acc: 0.9068 - val_loss: 0.2999 - val_acc: 0.8704\n",
      "Epoch 284/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1847 - acc: 0.9067 - val_loss: 0.2892 - val_acc: 0.8669\n",
      "Epoch 285/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1857 - acc: 0.9075 - val_loss: 0.2894 - val_acc: 0.8649\n",
      "Epoch 286/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1850 - acc: 0.9060 - val_loss: 0.2898 - val_acc: 0.8648\n",
      "Epoch 287/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1850 - acc: 0.9065 - val_loss: 0.3014 - val_acc: 0.8654\n",
      "Epoch 288/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1830 - acc: 0.9088 - val_loss: 0.3045 - val_acc: 0.8681\n",
      "Epoch 289/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1842 - acc: 0.9073 - val_loss: 0.2938 - val_acc: 0.8640\n",
      "Epoch 290/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1851 - acc: 0.9083 - val_loss: 0.2948 - val_acc: 0.8654\n",
      "Epoch 291/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1830 - acc: 0.9096 - val_loss: 0.2966 - val_acc: 0.8665\n",
      "Epoch 292/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1852 - acc: 0.9068 - val_loss: 0.2875 - val_acc: 0.8680\n",
      "Epoch 293/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1844 - acc: 0.9073 - val_loss: 0.2942 - val_acc: 0.8669\n",
      "Epoch 294/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1817 - acc: 0.9101 - val_loss: 0.3045 - val_acc: 0.8668\n",
      "Epoch 295/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1817 - acc: 0.9099 - val_loss: 0.2980 - val_acc: 0.8675\n",
      "Epoch 296/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1831 - acc: 0.9095 - val_loss: 0.3085 - val_acc: 0.8646\n",
      "Epoch 297/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1828 - acc: 0.9088 - val_loss: 0.2944 - val_acc: 0.8623\n",
      "Epoch 298/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1826 - acc: 0.9093 - val_loss: 0.3077 - val_acc: 0.8628\n",
      "Epoch 299/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1814 - acc: 0.9086 - val_loss: 0.3049 - val_acc: 0.8641\n",
      "Epoch 300/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1828 - acc: 0.9082 - val_loss: 0.3059 - val_acc: 0.8698\n",
      "Epoch 301/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1811 - acc: 0.9107 - val_loss: 0.3104 - val_acc: 0.8690\n",
      "Epoch 302/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1803 - acc: 0.9114 - val_loss: 0.3083 - val_acc: 0.8622\n",
      "Epoch 303/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1816 - acc: 0.9095 - val_loss: 0.3108 - val_acc: 0.8662\n",
      "Epoch 304/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1818 - acc: 0.9101 - val_loss: 0.3128 - val_acc: 0.8657\n",
      "Epoch 305/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1811 - acc: 0.9091 - val_loss: 0.3065 - val_acc: 0.8666\n",
      "Epoch 306/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1794 - acc: 0.9105 - val_loss: 0.3176 - val_acc: 0.8626\n",
      "Epoch 307/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1786 - acc: 0.9121 - val_loss: 0.3088 - val_acc: 0.8686\n",
      "Epoch 308/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1790 - acc: 0.9118 - val_loss: 0.3129 - val_acc: 0.8638\n",
      "Epoch 309/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1797 - acc: 0.9122 - val_loss: 0.3110 - val_acc: 0.8675\n",
      "Epoch 310/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1802 - acc: 0.9104 - val_loss: 0.3216 - val_acc: 0.8685\n",
      "Epoch 311/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1793 - acc: 0.9103 - val_loss: 0.3242 - val_acc: 0.8656\n",
      "Epoch 312/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1776 - acc: 0.9115 - val_loss: 0.3317 - val_acc: 0.8642\n",
      "Epoch 313/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1789 - acc: 0.9107 - val_loss: 0.3133 - val_acc: 0.8658\n",
      "Epoch 314/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1775 - acc: 0.9123 - val_loss: 0.3291 - val_acc: 0.8639\n",
      "Epoch 315/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1786 - acc: 0.9109 - val_loss: 0.3256 - val_acc: 0.8663\n",
      "Epoch 316/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1766 - acc: 0.9122 - val_loss: 0.3304 - val_acc: 0.8630\n",
      "Epoch 317/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1787 - acc: 0.9095 - val_loss: 0.3257 - val_acc: 0.8646\n",
      "Epoch 318/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1776 - acc: 0.9112 - val_loss: 0.3116 - val_acc: 0.8697\n",
      "Epoch 319/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1771 - acc: 0.9116 - val_loss: 0.3238 - val_acc: 0.8588\n",
      "Epoch 320/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1772 - acc: 0.9118 - val_loss: 0.3314 - val_acc: 0.8643\n",
      "Epoch 321/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1762 - acc: 0.9134 - val_loss: 0.3169 - val_acc: 0.8632\n",
      "Epoch 322/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1750 - acc: 0.9139 - val_loss: 0.3271 - val_acc: 0.8681\n",
      "Epoch 323/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1785 - acc: 0.9119 - val_loss: 0.3199 - val_acc: 0.8600\n",
      "Epoch 324/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1793 - acc: 0.9115 - val_loss: 0.3045 - val_acc: 0.8647\n",
      "Epoch 325/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1774 - acc: 0.9116 - val_loss: 0.3147 - val_acc: 0.8634\n",
      "Epoch 326/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1758 - acc: 0.9126 - val_loss: 0.3359 - val_acc: 0.8681\n",
      "Epoch 327/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1761 - acc: 0.9129 - val_loss: 0.3230 - val_acc: 0.8567\n",
      "Epoch 328/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1738 - acc: 0.9146 - val_loss: 0.3355 - val_acc: 0.8624\n",
      "Epoch 329/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1755 - acc: 0.9129 - val_loss: 0.3327 - val_acc: 0.8642\n",
      "Epoch 330/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1768 - acc: 0.9110 - val_loss: 0.3269 - val_acc: 0.8659\n",
      "Epoch 331/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1777 - acc: 0.9115 - val_loss: 0.3306 - val_acc: 0.8605\n",
      "Epoch 332/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1770 - acc: 0.9124 - val_loss: 0.3326 - val_acc: 0.8619\n",
      "Epoch 333/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1765 - acc: 0.9138 - val_loss: 0.3261 - val_acc: 0.8640\n",
      "Epoch 334/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1738 - acc: 0.9161 - val_loss: 0.3254 - val_acc: 0.8667\n",
      "Epoch 335/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1748 - acc: 0.9137 - val_loss: 0.3388 - val_acc: 0.8678\n",
      "Epoch 336/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1734 - acc: 0.9152 - val_loss: 0.3246 - val_acc: 0.8667\n",
      "Epoch 337/1000\n",
      "11086/11086 [==============================] - 0s 31us/step - loss: 0.1729 - acc: 0.9159 - val_loss: 0.3244 - val_acc: 0.8645\n",
      "Epoch 338/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1727 - acc: 0.9171 - val_loss: 0.3428 - val_acc: 0.8644\n",
      "Epoch 339/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1719 - acc: 0.9159 - val_loss: 0.3346 - val_acc: 0.8685\n",
      "Epoch 340/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1715 - acc: 0.9159 - val_loss: 0.3484 - val_acc: 0.8684\n",
      "Epoch 341/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1726 - acc: 0.9149 - val_loss: 0.3230 - val_acc: 0.8667\n",
      "Epoch 342/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1728 - acc: 0.9148 - val_loss: 0.3617 - val_acc: 0.8617\n",
      "Epoch 343/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1741 - acc: 0.9140 - val_loss: 0.3433 - val_acc: 0.8654\n",
      "Epoch 344/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1728 - acc: 0.9140 - val_loss: 0.3349 - val_acc: 0.8603\n",
      "Epoch 345/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1738 - acc: 0.9153 - val_loss: 0.3391 - val_acc: 0.8654\n",
      "Epoch 346/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1704 - acc: 0.9176 - val_loss: 0.3438 - val_acc: 0.8637\n",
      "Epoch 347/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1715 - acc: 0.9165 - val_loss: 0.3597 - val_acc: 0.8619\n",
      "Epoch 348/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1727 - acc: 0.9149 - val_loss: 0.3444 - val_acc: 0.8624\n",
      "Epoch 349/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1710 - acc: 0.9156 - val_loss: 0.3461 - val_acc: 0.8640\n",
      "Epoch 350/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1738 - acc: 0.9131 - val_loss: 0.3375 - val_acc: 0.8648\n",
      "Epoch 351/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1716 - acc: 0.9156 - val_loss: 0.3535 - val_acc: 0.8683\n",
      "Epoch 352/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1730 - acc: 0.9146 - val_loss: 0.3481 - val_acc: 0.8614\n",
      "Epoch 353/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1701 - acc: 0.9168 - val_loss: 0.3432 - val_acc: 0.8648\n",
      "Epoch 354/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1704 - acc: 0.9170 - val_loss: 0.3516 - val_acc: 0.8603\n",
      "Epoch 355/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1700 - acc: 0.9170 - val_loss: 0.3573 - val_acc: 0.8639\n",
      "Epoch 356/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1689 - acc: 0.9183 - val_loss: 0.3515 - val_acc: 0.8636\n",
      "Epoch 357/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1699 - acc: 0.9167 - val_loss: 0.3477 - val_acc: 0.8639\n",
      "Epoch 358/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1695 - acc: 0.9171 - val_loss: 0.3604 - val_acc: 0.8637\n",
      "Epoch 359/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1706 - acc: 0.9170 - val_loss: 0.3585 - val_acc: 0.8633\n",
      "Epoch 360/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1711 - acc: 0.9158 - val_loss: 0.3482 - val_acc: 0.8635\n",
      "Epoch 361/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1695 - acc: 0.9174 - val_loss: 0.3642 - val_acc: 0.8656\n",
      "Epoch 362/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1675 - acc: 0.9182 - val_loss: 0.3603 - val_acc: 0.8658\n",
      "Epoch 363/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1685 - acc: 0.9165 - val_loss: 0.3557 - val_acc: 0.8628\n",
      "Epoch 364/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1669 - acc: 0.9198 - val_loss: 0.3561 - val_acc: 0.8640\n",
      "Epoch 365/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1691 - acc: 0.9184 - val_loss: 0.3825 - val_acc: 0.8591\n",
      "Epoch 366/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1712 - acc: 0.9157 - val_loss: 0.3470 - val_acc: 0.8657\n",
      "Epoch 367/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1696 - acc: 0.9170 - val_loss: 0.3417 - val_acc: 0.8636\n",
      "Epoch 368/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1706 - acc: 0.9153 - val_loss: 0.3637 - val_acc: 0.8615\n",
      "Epoch 369/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1676 - acc: 0.9179 - val_loss: 0.3769 - val_acc: 0.8635\n",
      "Epoch 370/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1679 - acc: 0.9186 - val_loss: 0.3720 - val_acc: 0.8631\n",
      "Epoch 371/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1672 - acc: 0.9189 - val_loss: 0.3608 - val_acc: 0.8649\n",
      "Epoch 372/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1679 - acc: 0.9184 - val_loss: 0.3713 - val_acc: 0.8649\n",
      "Epoch 373/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1671 - acc: 0.9190 - val_loss: 0.3669 - val_acc: 0.8642\n",
      "Epoch 374/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1685 - acc: 0.9169 - val_loss: 0.3682 - val_acc: 0.8653\n",
      "Epoch 375/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1703 - acc: 0.9158 - val_loss: 0.3744 - val_acc: 0.8703\n",
      "Epoch 376/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1684 - acc: 0.9187 - val_loss: 0.3752 - val_acc: 0.8628\n",
      "Epoch 377/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1670 - acc: 0.9189 - val_loss: 0.3723 - val_acc: 0.8682\n",
      "Epoch 378/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1669 - acc: 0.9195 - val_loss: 0.3679 - val_acc: 0.8653\n",
      "Epoch 379/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1685 - acc: 0.9163 - val_loss: 0.3662 - val_acc: 0.8632\n",
      "Epoch 380/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1656 - acc: 0.9198 - val_loss: 0.3822 - val_acc: 0.8631\n",
      "Epoch 381/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1694 - acc: 0.9173 - val_loss: 0.3538 - val_acc: 0.8634\n",
      "Epoch 382/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1689 - acc: 0.9167 - val_loss: 0.3668 - val_acc: 0.8641\n",
      "Epoch 383/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1696 - acc: 0.9169 - val_loss: 0.3775 - val_acc: 0.8634\n",
      "Epoch 384/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1709 - acc: 0.9151 - val_loss: 0.3490 - val_acc: 0.8656\n",
      "Epoch 385/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1699 - acc: 0.9168 - val_loss: 0.3688 - val_acc: 0.8673\n",
      "Epoch 386/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1708 - acc: 0.9153 - val_loss: 0.3897 - val_acc: 0.8674\n",
      "Epoch 387/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1678 - acc: 0.9185 - val_loss: 0.3693 - val_acc: 0.8665\n",
      "Epoch 388/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1669 - acc: 0.9184 - val_loss: 0.3766 - val_acc: 0.8652\n",
      "Epoch 389/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1698 - acc: 0.9168 - val_loss: 0.3805 - val_acc: 0.8604\n",
      "Epoch 390/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1676 - acc: 0.9187 - val_loss: 0.3786 - val_acc: 0.8650\n",
      "Epoch 391/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1669 - acc: 0.9176 - val_loss: 0.3797 - val_acc: 0.8652\n",
      "Epoch 392/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1662 - acc: 0.9174 - val_loss: 0.3910 - val_acc: 0.8646\n",
      "Epoch 393/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1671 - acc: 0.9174 - val_loss: 0.3820 - val_acc: 0.8632\n",
      "Epoch 394/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1698 - acc: 0.9161 - val_loss: 0.3741 - val_acc: 0.8655\n",
      "Epoch 395/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1652 - acc: 0.9203 - val_loss: 0.3829 - val_acc: 0.8686\n",
      "Epoch 396/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1666 - acc: 0.9182 - val_loss: 0.3791 - val_acc: 0.8656\n",
      "Epoch 397/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1677 - acc: 0.9169 - val_loss: 0.3791 - val_acc: 0.8636\n",
      "Epoch 398/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1672 - acc: 0.9179 - val_loss: 0.3957 - val_acc: 0.8670\n",
      "Epoch 399/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1653 - acc: 0.9194 - val_loss: 0.3777 - val_acc: 0.8689\n",
      "Epoch 400/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1648 - acc: 0.9201 - val_loss: 0.3860 - val_acc: 0.8661\n",
      "Epoch 401/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1657 - acc: 0.9186 - val_loss: 0.3932 - val_acc: 0.8675\n",
      "Epoch 402/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1669 - acc: 0.9183 - val_loss: 0.3940 - val_acc: 0.8655\n",
      "Epoch 403/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1653 - acc: 0.9192 - val_loss: 0.4215 - val_acc: 0.8628\n",
      "Epoch 404/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1628 - acc: 0.9210 - val_loss: 0.4018 - val_acc: 0.8694\n",
      "Epoch 405/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1657 - acc: 0.9193 - val_loss: 0.3840 - val_acc: 0.8641\n",
      "Epoch 406/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1660 - acc: 0.9180 - val_loss: 0.3943 - val_acc: 0.8634\n",
      "Epoch 407/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1651 - acc: 0.9195 - val_loss: 0.4095 - val_acc: 0.8625\n",
      "Epoch 408/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1632 - acc: 0.9218 - val_loss: 0.4214 - val_acc: 0.8630\n",
      "Epoch 409/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1653 - acc: 0.9188 - val_loss: 0.3816 - val_acc: 0.8677\n",
      "Epoch 410/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1635 - acc: 0.9199 - val_loss: 0.4153 - val_acc: 0.8692\n",
      "Epoch 411/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1616 - acc: 0.9222 - val_loss: 0.4056 - val_acc: 0.8653\n",
      "Epoch 412/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1617 - acc: 0.9225 - val_loss: 0.4230 - val_acc: 0.8670\n",
      "Epoch 413/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1598 - acc: 0.9230 - val_loss: 0.4134 - val_acc: 0.8656\n",
      "Epoch 414/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1608 - acc: 0.9225 - val_loss: 0.4034 - val_acc: 0.8612\n",
      "Epoch 415/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1600 - acc: 0.9231 - val_loss: 0.4095 - val_acc: 0.8638\n",
      "Epoch 416/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1640 - acc: 0.9208 - val_loss: 0.4167 - val_acc: 0.8646\n",
      "Epoch 417/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1636 - acc: 0.9200 - val_loss: 0.4054 - val_acc: 0.8676\n",
      "Epoch 418/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1633 - acc: 0.9219 - val_loss: 0.3818 - val_acc: 0.8691\n",
      "Epoch 419/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1653 - acc: 0.9200 - val_loss: 0.3966 - val_acc: 0.8645\n",
      "Epoch 420/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1648 - acc: 0.9202 - val_loss: 0.4160 - val_acc: 0.8664\n",
      "Epoch 421/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1678 - acc: 0.9178 - val_loss: 0.3753 - val_acc: 0.8640\n",
      "Epoch 422/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1662 - acc: 0.9188 - val_loss: 0.4043 - val_acc: 0.8615\n",
      "Epoch 423/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1664 - acc: 0.9181 - val_loss: 0.3977 - val_acc: 0.8573\n",
      "Epoch 424/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1633 - acc: 0.9207 - val_loss: 0.4173 - val_acc: 0.8681\n",
      "Epoch 425/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1624 - acc: 0.9217 - val_loss: 0.4026 - val_acc: 0.8643\n",
      "Epoch 426/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1645 - acc: 0.9190 - val_loss: 0.3840 - val_acc: 0.8649\n",
      "Epoch 427/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1664 - acc: 0.9188 - val_loss: 0.3984 - val_acc: 0.8695\n",
      "Epoch 428/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1629 - acc: 0.9221 - val_loss: 0.4066 - val_acc: 0.8688\n",
      "Epoch 429/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1623 - acc: 0.9215 - val_loss: 0.4059 - val_acc: 0.8668\n",
      "Epoch 430/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1689 - acc: 0.9159 - val_loss: 0.3922 - val_acc: 0.8667\n",
      "Epoch 431/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1633 - acc: 0.9193 - val_loss: 0.4152 - val_acc: 0.8697\n",
      "Epoch 432/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1634 - acc: 0.9208 - val_loss: 0.4026 - val_acc: 0.8685\n",
      "Epoch 433/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1664 - acc: 0.9177 - val_loss: 0.3869 - val_acc: 0.8663\n",
      "Epoch 434/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1663 - acc: 0.9191 - val_loss: 0.4013 - val_acc: 0.8698\n",
      "Epoch 435/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1632 - acc: 0.9204 - val_loss: 0.4207 - val_acc: 0.8666\n",
      "Epoch 436/1000\n",
      "11086/11086 [==============================] - 0s 31us/step - loss: 0.1636 - acc: 0.9203 - val_loss: 0.4036 - val_acc: 0.8656\n",
      "Epoch 437/1000\n",
      "11086/11086 [==============================] - 0s 34us/step - loss: 0.1618 - acc: 0.9210 - val_loss: 0.3966 - val_acc: 0.8680\n",
      "Epoch 438/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1626 - acc: 0.9216 - val_loss: 0.4015 - val_acc: 0.8688\n",
      "Epoch 439/1000\n",
      "11086/11086 [==============================] - 0s 31us/step - loss: 0.1654 - acc: 0.9174 - val_loss: 0.4117 - val_acc: 0.8687\n",
      "Epoch 440/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1635 - acc: 0.9207 - val_loss: 0.4229 - val_acc: 0.8653\n",
      "Epoch 441/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1629 - acc: 0.9212 - val_loss: 0.4384 - val_acc: 0.8641\n",
      "Epoch 442/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1614 - acc: 0.9220 - val_loss: 0.4220 - val_acc: 0.8668\n",
      "Epoch 443/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1660 - acc: 0.9179 - val_loss: 0.4012 - val_acc: 0.8618\n",
      "Epoch 444/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1638 - acc: 0.9211 - val_loss: 0.3953 - val_acc: 0.8628\n",
      "Epoch 445/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1620 - acc: 0.9217 - val_loss: 0.4323 - val_acc: 0.8613\n",
      "Epoch 446/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1601 - acc: 0.9227 - val_loss: 0.4396 - val_acc: 0.8638\n",
      "Epoch 447/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1614 - acc: 0.9217 - val_loss: 0.4334 - val_acc: 0.8616\n",
      "Epoch 448/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1603 - acc: 0.9230 - val_loss: 0.4375 - val_acc: 0.8640\n",
      "Epoch 449/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1618 - acc: 0.9218 - val_loss: 0.4089 - val_acc: 0.8665\n",
      "Epoch 450/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1634 - acc: 0.9217 - val_loss: 0.4447 - val_acc: 0.8690\n",
      "Epoch 451/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1620 - acc: 0.9225 - val_loss: 0.4211 - val_acc: 0.8640\n",
      "Epoch 452/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1634 - acc: 0.9209 - val_loss: 0.4334 - val_acc: 0.8674\n",
      "Epoch 453/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1566 - acc: 0.9261 - val_loss: 0.4427 - val_acc: 0.8651\n",
      "Epoch 454/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1630 - acc: 0.9207 - val_loss: 0.4033 - val_acc: 0.8667\n",
      "Epoch 455/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1630 - acc: 0.9210 - val_loss: 0.4349 - val_acc: 0.8638\n",
      "Epoch 456/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1635 - acc: 0.9218 - val_loss: 0.3839 - val_acc: 0.8641\n",
      "Epoch 457/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1610 - acc: 0.9229 - val_loss: 0.4408 - val_acc: 0.8690\n",
      "Epoch 458/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1597 - acc: 0.9227 - val_loss: 0.4370 - val_acc: 0.8665\n",
      "Epoch 459/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1581 - acc: 0.9245 - val_loss: 0.4473 - val_acc: 0.8693\n",
      "Epoch 460/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1562 - acc: 0.9257 - val_loss: 0.4559 - val_acc: 0.8662\n",
      "Epoch 461/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1580 - acc: 0.9236 - val_loss: 0.4343 - val_acc: 0.8687\n",
      "Epoch 462/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1560 - acc: 0.9248 - val_loss: 0.4329 - val_acc: 0.8679\n",
      "Epoch 463/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1588 - acc: 0.9250 - val_loss: 0.4550 - val_acc: 0.8676\n",
      "Epoch 464/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1583 - acc: 0.9235 - val_loss: 0.4244 - val_acc: 0.8659\n",
      "Epoch 465/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1591 - acc: 0.9232 - val_loss: 0.4307 - val_acc: 0.8674\n",
      "Epoch 466/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1592 - acc: 0.9231 - val_loss: 0.4408 - val_acc: 0.8683\n",
      "Epoch 467/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1581 - acc: 0.9243 - val_loss: 0.4342 - val_acc: 0.8683\n",
      "Epoch 468/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1616 - acc: 0.9223 - val_loss: 0.4198 - val_acc: 0.8695\n",
      "Epoch 469/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1615 - acc: 0.9206 - val_loss: 0.4178 - val_acc: 0.8708\n",
      "Epoch 470/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1625 - acc: 0.9191 - val_loss: 0.4006 - val_acc: 0.8647\n",
      "Epoch 471/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1600 - acc: 0.9228 - val_loss: 0.4266 - val_acc: 0.8662\n",
      "Epoch 472/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1599 - acc: 0.9227 - val_loss: 0.4359 - val_acc: 0.8721\n",
      "Epoch 473/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1587 - acc: 0.9240 - val_loss: 0.4422 - val_acc: 0.8655\n",
      "Epoch 474/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1577 - acc: 0.9242 - val_loss: 0.4383 - val_acc: 0.8668\n",
      "Epoch 475/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1575 - acc: 0.9248 - val_loss: 0.4510 - val_acc: 0.8688\n",
      "Epoch 476/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1620 - acc: 0.9220 - val_loss: 0.4368 - val_acc: 0.8740\n",
      "Epoch 477/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1626 - acc: 0.9208 - val_loss: 0.4247 - val_acc: 0.8686\n",
      "Epoch 478/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1593 - acc: 0.9232 - val_loss: 0.4394 - val_acc: 0.8675\n",
      "Epoch 479/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1593 - acc: 0.9229 - val_loss: 0.4171 - val_acc: 0.8702\n",
      "Epoch 480/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1570 - acc: 0.9236 - val_loss: 0.4593 - val_acc: 0.8714\n",
      "Epoch 481/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1602 - acc: 0.9224 - val_loss: 0.4476 - val_acc: 0.8665\n",
      "Epoch 482/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1589 - acc: 0.9229 - val_loss: 0.4310 - val_acc: 0.8645\n",
      "Epoch 483/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1651 - acc: 0.9180 - val_loss: 0.4260 - val_acc: 0.8682\n",
      "Epoch 484/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1629 - acc: 0.9208 - val_loss: 0.4497 - val_acc: 0.8684\n",
      "Epoch 485/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1604 - acc: 0.9223 - val_loss: 0.4506 - val_acc: 0.8671\n",
      "Epoch 486/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1576 - acc: 0.9250 - val_loss: 0.4729 - val_acc: 0.8675\n",
      "Epoch 487/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1584 - acc: 0.9240 - val_loss: 0.4717 - val_acc: 0.8728\n",
      "Epoch 488/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1569 - acc: 0.9250 - val_loss: 0.4282 - val_acc: 0.8667\n",
      "Epoch 489/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1597 - acc: 0.9234 - val_loss: 0.4305 - val_acc: 0.8710\n",
      "Epoch 490/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1557 - acc: 0.9256 - val_loss: 0.4747 - val_acc: 0.8633\n",
      "Epoch 491/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1588 - acc: 0.9229 - val_loss: 0.4435 - val_acc: 0.8622\n",
      "Epoch 492/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1603 - acc: 0.9234 - val_loss: 0.4385 - val_acc: 0.8699\n",
      "Epoch 493/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1596 - acc: 0.9233 - val_loss: 0.3992 - val_acc: 0.8697\n",
      "Epoch 494/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1610 - acc: 0.9205 - val_loss: 0.4441 - val_acc: 0.8664\n",
      "Epoch 495/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1607 - acc: 0.9217 - val_loss: 0.4597 - val_acc: 0.8671\n",
      "Epoch 496/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1585 - acc: 0.9233 - val_loss: 0.4654 - val_acc: 0.8693\n",
      "Epoch 497/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1582 - acc: 0.9245 - val_loss: 0.4595 - val_acc: 0.8681\n",
      "Epoch 498/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1568 - acc: 0.9252 - val_loss: 0.4866 - val_acc: 0.8657\n",
      "Epoch 499/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1627 - acc: 0.9202 - val_loss: 0.4512 - val_acc: 0.8649\n",
      "Epoch 500/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1563 - acc: 0.9260 - val_loss: 0.4690 - val_acc: 0.8680\n",
      "Epoch 501/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1548 - acc: 0.9260 - val_loss: 0.4564 - val_acc: 0.8642\n",
      "Epoch 502/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1543 - acc: 0.9259 - val_loss: 0.4964 - val_acc: 0.8703\n",
      "Epoch 503/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1534 - acc: 0.9267 - val_loss: 0.4522 - val_acc: 0.8705\n",
      "Epoch 504/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1605 - acc: 0.9214 - val_loss: 0.4478 - val_acc: 0.8682\n",
      "Epoch 505/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1581 - acc: 0.9238 - val_loss: 0.4763 - val_acc: 0.8673\n",
      "Epoch 506/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1575 - acc: 0.9232 - val_loss: 0.4761 - val_acc: 0.8698\n",
      "Epoch 507/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1537 - acc: 0.9259 - val_loss: 0.4603 - val_acc: 0.8641\n",
      "Epoch 508/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1566 - acc: 0.9230 - val_loss: 0.4596 - val_acc: 0.8658\n",
      "Epoch 509/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1572 - acc: 0.9251 - val_loss: 0.4766 - val_acc: 0.8673\n",
      "Epoch 510/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1578 - acc: 0.9245 - val_loss: 0.4827 - val_acc: 0.8680\n",
      "Epoch 511/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1585 - acc: 0.9235 - val_loss: 0.4602 - val_acc: 0.8607\n",
      "Epoch 512/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1578 - acc: 0.9242 - val_loss: 0.4342 - val_acc: 0.8723\n",
      "Epoch 513/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1589 - acc: 0.9253 - val_loss: 0.4460 - val_acc: 0.8663\n",
      "Epoch 514/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1570 - acc: 0.9251 - val_loss: 0.4493 - val_acc: 0.8662\n",
      "Epoch 515/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1596 - acc: 0.9222 - val_loss: 0.4725 - val_acc: 0.8707\n",
      "Epoch 516/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1576 - acc: 0.9232 - val_loss: 0.4647 - val_acc: 0.8691\n",
      "Epoch 517/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1595 - acc: 0.9229 - val_loss: 0.4261 - val_acc: 0.8666\n",
      "Epoch 518/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1579 - acc: 0.9232 - val_loss: 0.4805 - val_acc: 0.8711\n",
      "Epoch 519/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1584 - acc: 0.9238 - val_loss: 0.4374 - val_acc: 0.8670\n",
      "Epoch 520/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1567 - acc: 0.9243 - val_loss: 0.4642 - val_acc: 0.8680\n",
      "Epoch 521/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1572 - acc: 0.9248 - val_loss: 0.4798 - val_acc: 0.8698\n",
      "Epoch 522/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1568 - acc: 0.9231 - val_loss: 0.4777 - val_acc: 0.8698\n",
      "Epoch 523/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1585 - acc: 0.9243 - val_loss: 0.4590 - val_acc: 0.8699\n",
      "Epoch 524/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1569 - acc: 0.9242 - val_loss: 0.5088 - val_acc: 0.8697\n",
      "Epoch 525/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1563 - acc: 0.9252 - val_loss: 0.4711 - val_acc: 0.8648\n",
      "Epoch 526/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1551 - acc: 0.9255 - val_loss: 0.4776 - val_acc: 0.8694\n",
      "Epoch 527/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1572 - acc: 0.9249 - val_loss: 0.4578 - val_acc: 0.8667\n",
      "Epoch 528/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1589 - acc: 0.9219 - val_loss: 0.4545 - val_acc: 0.8692\n",
      "Epoch 529/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1594 - acc: 0.9226 - val_loss: 0.4635 - val_acc: 0.8712\n",
      "Epoch 530/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1574 - acc: 0.9232 - val_loss: 0.4751 - val_acc: 0.8656\n",
      "Epoch 531/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1559 - acc: 0.9258 - val_loss: 0.4875 - val_acc: 0.8654\n",
      "Epoch 532/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1566 - acc: 0.9248 - val_loss: 0.4838 - val_acc: 0.8664\n",
      "Epoch 533/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1576 - acc: 0.9239 - val_loss: 0.5128 - val_acc: 0.8704\n",
      "Epoch 534/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1561 - acc: 0.9243 - val_loss: 0.5010 - val_acc: 0.8673\n",
      "Epoch 535/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1547 - acc: 0.9256 - val_loss: 0.4990 - val_acc: 0.8700\n",
      "Epoch 536/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1535 - acc: 0.9269 - val_loss: 0.4842 - val_acc: 0.8683\n",
      "Epoch 537/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1552 - acc: 0.9259 - val_loss: 0.4897 - val_acc: 0.8703\n",
      "Epoch 538/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1555 - acc: 0.9267 - val_loss: 0.4821 - val_acc: 0.8664\n",
      "Epoch 539/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1533 - acc: 0.9270 - val_loss: 0.5017 - val_acc: 0.8700\n",
      "Epoch 540/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1528 - acc: 0.9287 - val_loss: 0.4970 - val_acc: 0.8699\n",
      "Epoch 541/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1541 - acc: 0.9257 - val_loss: 0.5067 - val_acc: 0.8719\n",
      "Epoch 542/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1565 - acc: 0.9246 - val_loss: 0.5002 - val_acc: 0.8670\n",
      "Epoch 543/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1589 - acc: 0.9231 - val_loss: 0.4455 - val_acc: 0.8705\n",
      "Epoch 544/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1573 - acc: 0.9231 - val_loss: 0.4866 - val_acc: 0.8691\n",
      "Epoch 545/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1552 - acc: 0.9254 - val_loss: 0.4628 - val_acc: 0.8678\n",
      "Epoch 546/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1563 - acc: 0.9237 - val_loss: 0.4978 - val_acc: 0.8677\n",
      "Epoch 547/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1562 - acc: 0.9233 - val_loss: 0.5065 - val_acc: 0.8680\n",
      "Epoch 548/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1511 - acc: 0.9285 - val_loss: 0.4744 - val_acc: 0.8712\n",
      "Epoch 549/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1549 - acc: 0.9255 - val_loss: 0.5308 - val_acc: 0.8659\n",
      "Epoch 550/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1507 - acc: 0.9290 - val_loss: 0.5267 - val_acc: 0.8679\n",
      "Epoch 551/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1520 - acc: 0.9269 - val_loss: 0.5056 - val_acc: 0.8660\n",
      "Epoch 552/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1536 - acc: 0.9253 - val_loss: 0.4933 - val_acc: 0.8674\n",
      "Epoch 553/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1539 - acc: 0.9254 - val_loss: 0.5188 - val_acc: 0.8677\n",
      "Epoch 554/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1566 - acc: 0.9241 - val_loss: 0.4985 - val_acc: 0.8725\n",
      "Epoch 555/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1594 - acc: 0.9229 - val_loss: 0.4704 - val_acc: 0.8700\n",
      "Epoch 556/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1552 - acc: 0.9246 - val_loss: 0.4470 - val_acc: 0.8714\n",
      "Epoch 557/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1598 - acc: 0.9205 - val_loss: 0.4955 - val_acc: 0.8683\n",
      "Epoch 558/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1556 - acc: 0.9242 - val_loss: 0.4943 - val_acc: 0.8711\n",
      "Epoch 559/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1535 - acc: 0.9268 - val_loss: 0.5232 - val_acc: 0.8705\n",
      "Epoch 560/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1560 - acc: 0.9254 - val_loss: 0.5291 - val_acc: 0.8696\n",
      "Epoch 561/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1541 - acc: 0.9267 - val_loss: 0.4834 - val_acc: 0.8657\n",
      "Epoch 562/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1564 - acc: 0.9254 - val_loss: 0.5132 - val_acc: 0.8677\n",
      "Epoch 563/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1512 - acc: 0.9284 - val_loss: 0.5222 - val_acc: 0.8708\n",
      "Epoch 564/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1541 - acc: 0.9260 - val_loss: 0.4828 - val_acc: 0.8655\n",
      "Epoch 565/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1528 - acc: 0.9281 - val_loss: 0.4766 - val_acc: 0.8697\n",
      "Epoch 566/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1563 - acc: 0.9259 - val_loss: 0.5226 - val_acc: 0.8633\n",
      "Epoch 567/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1563 - acc: 0.9243 - val_loss: 0.5430 - val_acc: 0.8650\n",
      "Epoch 568/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1511 - acc: 0.9295 - val_loss: 0.5621 - val_acc: 0.8648\n",
      "Epoch 569/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1492 - acc: 0.9300 - val_loss: 0.5406 - val_acc: 0.8684\n",
      "Epoch 570/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1528 - acc: 0.9287 - val_loss: 0.4973 - val_acc: 0.8695\n",
      "Epoch 571/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1560 - acc: 0.9244 - val_loss: 0.4797 - val_acc: 0.8693\n",
      "Epoch 572/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1598 - acc: 0.9224 - val_loss: 0.5331 - val_acc: 0.8668\n",
      "Epoch 573/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1507 - acc: 0.9282 - val_loss: 0.5244 - val_acc: 0.8683\n",
      "Epoch 574/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1518 - acc: 0.9288 - val_loss: 0.5599 - val_acc: 0.8663\n",
      "Epoch 575/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1510 - acc: 0.9292 - val_loss: 0.5138 - val_acc: 0.8688\n",
      "Epoch 576/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1572 - acc: 0.9230 - val_loss: 0.4610 - val_acc: 0.8717\n",
      "Epoch 577/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1560 - acc: 0.9248 - val_loss: 0.4871 - val_acc: 0.8666\n",
      "Epoch 578/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1588 - acc: 0.9221 - val_loss: 0.4802 - val_acc: 0.8646\n",
      "Epoch 579/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1524 - acc: 0.9268 - val_loss: 0.5400 - val_acc: 0.8647\n",
      "Epoch 580/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1530 - acc: 0.9260 - val_loss: 0.5503 - val_acc: 0.8707\n",
      "Epoch 581/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1567 - acc: 0.9242 - val_loss: 0.4856 - val_acc: 0.8617\n",
      "Epoch 582/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1533 - acc: 0.9273 - val_loss: 0.4986 - val_acc: 0.8668\n",
      "Epoch 583/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1557 - acc: 0.9241 - val_loss: 0.5195 - val_acc: 0.8661\n",
      "Epoch 584/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1560 - acc: 0.9240 - val_loss: 0.5221 - val_acc: 0.8660\n",
      "Epoch 585/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1554 - acc: 0.9245 - val_loss: 0.5143 - val_acc: 0.8700\n",
      "Epoch 586/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1559 - acc: 0.9251 - val_loss: 0.4981 - val_acc: 0.8700\n",
      "Epoch 587/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1575 - acc: 0.9236 - val_loss: 0.5024 - val_acc: 0.8661\n",
      "Epoch 588/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1580 - acc: 0.9228 - val_loss: 0.4851 - val_acc: 0.8667\n",
      "Epoch 589/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1578 - acc: 0.9213 - val_loss: 0.4974 - val_acc: 0.8664\n",
      "Epoch 590/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1577 - acc: 0.9215 - val_loss: 0.4698 - val_acc: 0.8728\n",
      "Epoch 591/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1585 - acc: 0.9231 - val_loss: 0.4824 - val_acc: 0.8661\n",
      "Epoch 592/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1584 - acc: 0.9221 - val_loss: 0.5344 - val_acc: 0.8682\n",
      "Epoch 593/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1560 - acc: 0.9249 - val_loss: 0.5351 - val_acc: 0.8689\n",
      "Epoch 594/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1572 - acc: 0.9228 - val_loss: 0.4572 - val_acc: 0.8685\n",
      "Epoch 595/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1585 - acc: 0.9228 - val_loss: 0.5208 - val_acc: 0.8692\n",
      "Epoch 596/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1561 - acc: 0.9232 - val_loss: 0.5216 - val_acc: 0.8704\n",
      "Epoch 597/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1532 - acc: 0.9259 - val_loss: 0.5354 - val_acc: 0.8715\n",
      "Epoch 598/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1493 - acc: 0.9289 - val_loss: 0.5275 - val_acc: 0.8680\n",
      "Epoch 599/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1500 - acc: 0.9280 - val_loss: 0.5390 - val_acc: 0.8689\n",
      "Epoch 600/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1552 - acc: 0.9234 - val_loss: 0.4716 - val_acc: 0.8668\n",
      "Epoch 601/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1571 - acc: 0.9214 - val_loss: 0.5378 - val_acc: 0.8691\n",
      "Epoch 602/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1529 - acc: 0.9256 - val_loss: 0.5576 - val_acc: 0.8705\n",
      "Epoch 603/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1557 - acc: 0.9255 - val_loss: 0.5208 - val_acc: 0.8636\n",
      "Epoch 604/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1539 - acc: 0.9258 - val_loss: 0.5313 - val_acc: 0.8657\n",
      "Epoch 605/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1550 - acc: 0.9253 - val_loss: 0.5556 - val_acc: 0.8693\n",
      "Epoch 606/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1564 - acc: 0.9242 - val_loss: 0.5539 - val_acc: 0.8646\n",
      "Epoch 607/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1574 - acc: 0.9243 - val_loss: 0.5385 - val_acc: 0.8650\n",
      "Epoch 608/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1519 - acc: 0.9259 - val_loss: 0.5359 - val_acc: 0.8681\n",
      "Epoch 609/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1551 - acc: 0.9235 - val_loss: 0.5273 - val_acc: 0.8656\n",
      "Epoch 610/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1508 - acc: 0.9288 - val_loss: 0.5539 - val_acc: 0.8712\n",
      "Epoch 611/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1543 - acc: 0.9254 - val_loss: 0.5040 - val_acc: 0.8700\n",
      "Epoch 612/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1513 - acc: 0.9277 - val_loss: 0.5482 - val_acc: 0.8730\n",
      "Epoch 613/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1527 - acc: 0.9267 - val_loss: 0.5019 - val_acc: 0.8694\n",
      "Epoch 614/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1518 - acc: 0.9251 - val_loss: 0.5350 - val_acc: 0.8691\n",
      "Epoch 615/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1553 - acc: 0.9240 - val_loss: 0.5229 - val_acc: 0.8668\n",
      "Epoch 616/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1538 - acc: 0.9245 - val_loss: 0.5335 - val_acc: 0.8685\n",
      "Epoch 617/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1563 - acc: 0.9243 - val_loss: 0.5038 - val_acc: 0.8638\n",
      "Epoch 618/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1572 - acc: 0.9226 - val_loss: 0.4699 - val_acc: 0.8682\n",
      "Epoch 619/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1563 - acc: 0.9238 - val_loss: 0.5942 - val_acc: 0.8712\n",
      "Epoch 620/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1560 - acc: 0.9241 - val_loss: 0.5530 - val_acc: 0.8670\n",
      "Epoch 621/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1498 - acc: 0.9283 - val_loss: 0.5476 - val_acc: 0.8697\n",
      "Epoch 622/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1504 - acc: 0.9286 - val_loss: 0.5784 - val_acc: 0.8758\n",
      "Epoch 623/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1533 - acc: 0.9253 - val_loss: 0.5177 - val_acc: 0.8656\n",
      "Epoch 624/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1528 - acc: 0.9278 - val_loss: 0.5435 - val_acc: 0.8703\n",
      "Epoch 625/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1515 - acc: 0.9266 - val_loss: 0.5271 - val_acc: 0.8735\n",
      "Epoch 626/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1518 - acc: 0.9275 - val_loss: 0.5807 - val_acc: 0.8677\n",
      "Epoch 627/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1477 - acc: 0.9299 - val_loss: 0.5699 - val_acc: 0.8707\n",
      "Epoch 628/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1503 - acc: 0.9283 - val_loss: 0.5461 - val_acc: 0.8721\n",
      "Epoch 629/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1481 - acc: 0.9298 - val_loss: 0.6245 - val_acc: 0.8733\n",
      "Epoch 630/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1499 - acc: 0.9286 - val_loss: 0.5385 - val_acc: 0.8693\n",
      "Epoch 631/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1550 - acc: 0.9254 - val_loss: 0.4825 - val_acc: 0.8645\n",
      "Epoch 632/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1545 - acc: 0.9247 - val_loss: 0.5447 - val_acc: 0.8702\n",
      "Epoch 633/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1572 - acc: 0.9237 - val_loss: 0.5086 - val_acc: 0.8680\n",
      "Epoch 634/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1534 - acc: 0.9249 - val_loss: 0.5377 - val_acc: 0.8718\n",
      "Epoch 635/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1562 - acc: 0.9223 - val_loss: 0.5008 - val_acc: 0.8729\n",
      "Epoch 636/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1562 - acc: 0.9228 - val_loss: 0.5237 - val_acc: 0.8730\n",
      "Epoch 637/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1599 - acc: 0.9237 - val_loss: 0.5127 - val_acc: 0.8720\n",
      "Epoch 638/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1499 - acc: 0.9291 - val_loss: 0.5459 - val_acc: 0.8708\n",
      "Epoch 639/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1550 - acc: 0.9268 - val_loss: 0.5388 - val_acc: 0.8705\n",
      "Epoch 640/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1501 - acc: 0.9288 - val_loss: 0.5416 - val_acc: 0.8697\n",
      "Epoch 641/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1504 - acc: 0.9276 - val_loss: 0.5396 - val_acc: 0.8701\n",
      "Epoch 642/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1497 - acc: 0.9289 - val_loss: 0.5634 - val_acc: 0.8756\n",
      "Epoch 643/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1513 - acc: 0.9271 - val_loss: 0.5874 - val_acc: 0.8738\n",
      "Epoch 644/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1541 - acc: 0.9252 - val_loss: 0.5672 - val_acc: 0.8678\n",
      "Epoch 645/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1505 - acc: 0.9279 - val_loss: 0.5488 - val_acc: 0.8748\n",
      "Epoch 646/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1498 - acc: 0.9290 - val_loss: 0.5691 - val_acc: 0.8678\n",
      "Epoch 647/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1487 - acc: 0.9283 - val_loss: 0.5163 - val_acc: 0.8676\n",
      "Epoch 648/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1518 - acc: 0.9267 - val_loss: 0.5765 - val_acc: 0.8695\n",
      "Epoch 649/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1461 - acc: 0.9315 - val_loss: 0.5702 - val_acc: 0.8730\n",
      "Epoch 650/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1509 - acc: 0.9262 - val_loss: 0.5450 - val_acc: 0.8709\n",
      "Epoch 651/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1548 - acc: 0.9240 - val_loss: 0.5631 - val_acc: 0.8650\n",
      "Epoch 652/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1525 - acc: 0.9248 - val_loss: 0.5506 - val_acc: 0.8718\n",
      "Epoch 653/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1541 - acc: 0.9261 - val_loss: 0.5837 - val_acc: 0.8704\n",
      "Epoch 654/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1523 - acc: 0.9261 - val_loss: 0.5699 - val_acc: 0.8681\n",
      "Epoch 655/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1446 - acc: 0.9309 - val_loss: 0.6085 - val_acc: 0.8708\n",
      "Epoch 656/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1514 - acc: 0.9264 - val_loss: 0.5571 - val_acc: 0.8686\n",
      "Epoch 657/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1502 - acc: 0.9275 - val_loss: 0.5041 - val_acc: 0.8704\n",
      "Epoch 658/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1550 - acc: 0.9241 - val_loss: 0.5199 - val_acc: 0.8712\n",
      "Epoch 659/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1542 - acc: 0.9244 - val_loss: 0.5401 - val_acc: 0.8684\n",
      "Epoch 660/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1508 - acc: 0.9272 - val_loss: 0.5492 - val_acc: 0.8661\n",
      "Epoch 661/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1585 - acc: 0.9209 - val_loss: 0.5237 - val_acc: 0.8695\n",
      "Epoch 662/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1546 - acc: 0.9237 - val_loss: 0.5409 - val_acc: 0.8658\n",
      "Epoch 663/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1566 - acc: 0.9238 - val_loss: 0.5081 - val_acc: 0.8719\n",
      "Epoch 664/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1598 - acc: 0.9218 - val_loss: 0.5560 - val_acc: 0.8701\n",
      "Epoch 665/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1581 - acc: 0.9212 - val_loss: 0.5431 - val_acc: 0.8726\n",
      "Epoch 666/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1543 - acc: 0.9244 - val_loss: 0.5254 - val_acc: 0.8747\n",
      "Epoch 667/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1581 - acc: 0.9207 - val_loss: 0.5150 - val_acc: 0.8682\n",
      "Epoch 668/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1559 - acc: 0.9253 - val_loss: 0.5168 - val_acc: 0.8666\n",
      "Epoch 669/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1530 - acc: 0.9266 - val_loss: 0.5560 - val_acc: 0.8660\n",
      "Epoch 670/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1587 - acc: 0.9242 - val_loss: 0.5324 - val_acc: 0.8715\n",
      "Epoch 671/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1558 - acc: 0.9268 - val_loss: 0.5083 - val_acc: 0.8707\n",
      "Epoch 672/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1531 - acc: 0.9277 - val_loss: 0.5646 - val_acc: 0.8702\n",
      "Epoch 673/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1542 - acc: 0.9285 - val_loss: 0.5522 - val_acc: 0.8697\n",
      "Epoch 674/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1547 - acc: 0.9251 - val_loss: 0.5614 - val_acc: 0.8731\n",
      "Epoch 675/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1520 - acc: 0.9274 - val_loss: 0.5584 - val_acc: 0.8695\n",
      "Epoch 676/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1582 - acc: 0.9228 - val_loss: 0.5278 - val_acc: 0.8673\n",
      "Epoch 677/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1587 - acc: 0.9246 - val_loss: 0.5101 - val_acc: 0.8671\n",
      "Epoch 678/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1565 - acc: 0.9258 - val_loss: 0.5210 - val_acc: 0.8703\n",
      "Epoch 679/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1536 - acc: 0.9276 - val_loss: 0.5495 - val_acc: 0.8716\n",
      "Epoch 680/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1553 - acc: 0.9262 - val_loss: 0.5237 - val_acc: 0.8698\n",
      "Epoch 681/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1571 - acc: 0.9237 - val_loss: 0.5605 - val_acc: 0.8684\n",
      "Epoch 682/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1582 - acc: 0.9239 - val_loss: 0.5373 - val_acc: 0.8686\n",
      "Epoch 683/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1565 - acc: 0.9258 - val_loss: 0.5381 - val_acc: 0.8663\n",
      "Epoch 684/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1526 - acc: 0.9298 - val_loss: 0.5960 - val_acc: 0.8694\n",
      "Epoch 685/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1534 - acc: 0.9277 - val_loss: 0.5628 - val_acc: 0.8666\n",
      "Epoch 686/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1534 - acc: 0.9282 - val_loss: 0.5795 - val_acc: 0.8655\n",
      "Epoch 687/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1584 - acc: 0.9242 - val_loss: 0.4829 - val_acc: 0.8660\n",
      "Epoch 688/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1589 - acc: 0.9239 - val_loss: 0.5288 - val_acc: 0.8675\n",
      "Epoch 689/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1547 - acc: 0.9274 - val_loss: 0.5253 - val_acc: 0.8689\n",
      "Epoch 690/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1584 - acc: 0.9246 - val_loss: 0.5617 - val_acc: 0.8644\n",
      "Epoch 691/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1571 - acc: 0.9248 - val_loss: 0.5277 - val_acc: 0.8702\n",
      "Epoch 692/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1558 - acc: 0.9259 - val_loss: 0.5866 - val_acc: 0.8710\n",
      "Epoch 693/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1585 - acc: 0.9246 - val_loss: 0.5291 - val_acc: 0.8688\n",
      "Epoch 694/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1562 - acc: 0.9253 - val_loss: 0.5725 - val_acc: 0.8693\n",
      "Epoch 695/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1549 - acc: 0.9260 - val_loss: 0.5698 - val_acc: 0.8684\n",
      "Epoch 696/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1535 - acc: 0.9269 - val_loss: 0.5533 - val_acc: 0.8725\n",
      "Epoch 697/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1520 - acc: 0.9288 - val_loss: 0.6174 - val_acc: 0.8674\n",
      "Epoch 698/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1516 - acc: 0.9296 - val_loss: 0.5411 - val_acc: 0.8730\n",
      "Epoch 699/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1516 - acc: 0.9293 - val_loss: 0.5789 - val_acc: 0.8737\n",
      "Epoch 700/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1521 - acc: 0.9297 - val_loss: 0.5913 - val_acc: 0.8711\n",
      "Epoch 701/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1530 - acc: 0.9273 - val_loss: 0.5176 - val_acc: 0.8681\n",
      "Epoch 702/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1547 - acc: 0.9273 - val_loss: 0.6057 - val_acc: 0.8722\n",
      "Epoch 703/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1541 - acc: 0.9277 - val_loss: 0.5731 - val_acc: 0.8734\n",
      "Epoch 704/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1531 - acc: 0.9267 - val_loss: 0.5578 - val_acc: 0.8730\n",
      "Epoch 705/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1516 - acc: 0.9277 - val_loss: 0.5640 - val_acc: 0.8691\n",
      "Epoch 706/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1518 - acc: 0.9277 - val_loss: 0.5728 - val_acc: 0.8698\n",
      "Epoch 707/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1548 - acc: 0.9242 - val_loss: 0.5655 - val_acc: 0.8753\n",
      "Epoch 708/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1523 - acc: 0.9283 - val_loss: 0.5815 - val_acc: 0.8719\n",
      "Epoch 709/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1504 - acc: 0.9289 - val_loss: 0.5971 - val_acc: 0.8727\n",
      "Epoch 710/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1529 - acc: 0.9263 - val_loss: 0.5369 - val_acc: 0.8708\n",
      "Epoch 711/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1543 - acc: 0.9229 - val_loss: 0.5587 - val_acc: 0.8752\n",
      "Epoch 712/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1538 - acc: 0.9272 - val_loss: 0.5831 - val_acc: 0.8689\n",
      "Epoch 713/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1545 - acc: 0.9259 - val_loss: 0.5514 - val_acc: 0.8702\n",
      "Epoch 714/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1560 - acc: 0.9258 - val_loss: 0.5379 - val_acc: 0.8756\n",
      "Epoch 715/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1563 - acc: 0.9256 - val_loss: 0.5358 - val_acc: 0.8694\n",
      "Epoch 716/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1563 - acc: 0.9266 - val_loss: 0.5352 - val_acc: 0.8704\n",
      "Epoch 717/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1537 - acc: 0.9262 - val_loss: 0.5470 - val_acc: 0.8729\n",
      "Epoch 718/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1504 - acc: 0.9300 - val_loss: 0.5604 - val_acc: 0.8723\n",
      "Epoch 719/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1523 - acc: 0.9274 - val_loss: 0.5956 - val_acc: 0.8732\n",
      "Epoch 720/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1540 - acc: 0.9247 - val_loss: 0.5705 - val_acc: 0.8745\n",
      "Epoch 721/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1512 - acc: 0.9297 - val_loss: 0.5791 - val_acc: 0.8714\n",
      "Epoch 722/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1565 - acc: 0.9258 - val_loss: 0.5279 - val_acc: 0.8725\n",
      "Epoch 723/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1556 - acc: 0.9253 - val_loss: 0.5511 - val_acc: 0.8688\n",
      "Epoch 724/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1548 - acc: 0.9257 - val_loss: 0.5474 - val_acc: 0.8645\n",
      "Epoch 725/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1574 - acc: 0.9256 - val_loss: 0.5436 - val_acc: 0.8677\n",
      "Epoch 726/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1559 - acc: 0.9256 - val_loss: 0.5305 - val_acc: 0.8715\n",
      "Epoch 727/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1577 - acc: 0.9244 - val_loss: 0.5008 - val_acc: 0.8674\n",
      "Epoch 728/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1528 - acc: 0.9274 - val_loss: 0.5553 - val_acc: 0.8708\n",
      "Epoch 729/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1525 - acc: 0.9279 - val_loss: 0.5686 - val_acc: 0.8739\n",
      "Epoch 730/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1564 - acc: 0.9251 - val_loss: 0.5580 - val_acc: 0.8702\n",
      "Epoch 731/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1541 - acc: 0.9270 - val_loss: 0.5826 - val_acc: 0.8729\n",
      "Epoch 732/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1528 - acc: 0.9282 - val_loss: 0.6018 - val_acc: 0.8708\n",
      "Epoch 733/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1502 - acc: 0.9298 - val_loss: 0.6041 - val_acc: 0.8687\n",
      "Epoch 734/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1562 - acc: 0.9259 - val_loss: 0.6060 - val_acc: 0.8659\n",
      "Epoch 735/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1530 - acc: 0.9267 - val_loss: 0.6421 - val_acc: 0.8705\n",
      "Epoch 736/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1577 - acc: 0.9235 - val_loss: 0.5288 - val_acc: 0.8665\n",
      "Epoch 737/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1560 - acc: 0.9251 - val_loss: 0.6158 - val_acc: 0.8684\n",
      "Epoch 738/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1522 - acc: 0.9283 - val_loss: 0.5777 - val_acc: 0.8694\n",
      "Epoch 739/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1536 - acc: 0.9282 - val_loss: 0.5878 - val_acc: 0.8688\n",
      "Epoch 740/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1529 - acc: 0.9282 - val_loss: 0.6363 - val_acc: 0.8649\n",
      "Epoch 741/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1508 - acc: 0.9297 - val_loss: 0.5820 - val_acc: 0.8728\n",
      "Epoch 742/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1543 - acc: 0.9272 - val_loss: 0.5524 - val_acc: 0.8698\n",
      "Epoch 743/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1507 - acc: 0.9293 - val_loss: 0.5979 - val_acc: 0.8658\n",
      "Epoch 744/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1512 - acc: 0.9287 - val_loss: 0.6159 - val_acc: 0.8641\n",
      "Epoch 745/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1550 - acc: 0.9262 - val_loss: 0.5938 - val_acc: 0.8659\n",
      "Epoch 746/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1544 - acc: 0.9272 - val_loss: 0.6052 - val_acc: 0.8619\n",
      "Epoch 747/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1534 - acc: 0.9281 - val_loss: 0.5766 - val_acc: 0.8670\n",
      "Epoch 748/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1587 - acc: 0.9238 - val_loss: 0.5486 - val_acc: 0.8636\n",
      "Epoch 749/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1617 - acc: 0.9219 - val_loss: 0.5817 - val_acc: 0.8686\n",
      "Epoch 750/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1580 - acc: 0.9246 - val_loss: 0.5374 - val_acc: 0.8668\n",
      "Epoch 751/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1633 - acc: 0.9207 - val_loss: 0.4882 - val_acc: 0.8670\n",
      "Epoch 752/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1542 - acc: 0.9266 - val_loss: 0.5767 - val_acc: 0.8641\n",
      "Epoch 753/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1548 - acc: 0.9278 - val_loss: 0.5886 - val_acc: 0.8697\n",
      "Epoch 754/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1576 - acc: 0.9246 - val_loss: 0.5885 - val_acc: 0.8661\n",
      "Epoch 755/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1545 - acc: 0.9268 - val_loss: 0.5895 - val_acc: 0.8655\n",
      "Epoch 756/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1547 - acc: 0.9260 - val_loss: 0.5762 - val_acc: 0.8639\n",
      "Epoch 757/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1507 - acc: 0.9283 - val_loss: 0.6060 - val_acc: 0.8690\n",
      "Epoch 758/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1521 - acc: 0.9266 - val_loss: 0.5689 - val_acc: 0.8648\n",
      "Epoch 759/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1516 - acc: 0.9268 - val_loss: 0.5950 - val_acc: 0.8666\n",
      "Epoch 760/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1511 - acc: 0.9272 - val_loss: 0.6070 - val_acc: 0.8753\n",
      "Epoch 761/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1501 - acc: 0.9270 - val_loss: 0.5959 - val_acc: 0.8691\n",
      "Epoch 762/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1542 - acc: 0.9249 - val_loss: 0.5521 - val_acc: 0.8685\n",
      "Epoch 763/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1586 - acc: 0.9220 - val_loss: 0.5885 - val_acc: 0.8663\n",
      "Epoch 764/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1563 - acc: 0.9220 - val_loss: 0.5705 - val_acc: 0.8681\n",
      "Epoch 765/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1556 - acc: 0.9233 - val_loss: 0.5882 - val_acc: 0.8685\n",
      "Epoch 766/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1548 - acc: 0.9266 - val_loss: 0.6054 - val_acc: 0.8702\n",
      "Epoch 767/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1494 - acc: 0.9275 - val_loss: 0.6259 - val_acc: 0.8713\n",
      "Epoch 768/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1509 - acc: 0.9260 - val_loss: 0.6078 - val_acc: 0.8687\n",
      "Epoch 769/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1508 - acc: 0.9269 - val_loss: 0.6008 - val_acc: 0.8662\n",
      "Epoch 770/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1523 - acc: 0.9278 - val_loss: 0.5974 - val_acc: 0.8663\n",
      "Epoch 771/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1519 - acc: 0.9296 - val_loss: 0.5747 - val_acc: 0.8690\n",
      "Epoch 772/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1558 - acc: 0.9257 - val_loss: 0.5365 - val_acc: 0.8714\n",
      "Epoch 773/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1604 - acc: 0.9223 - val_loss: 0.5564 - val_acc: 0.8637\n",
      "Epoch 774/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1580 - acc: 0.9252 - val_loss: 0.5903 - val_acc: 0.8647\n",
      "Epoch 775/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1503 - acc: 0.9302 - val_loss: 0.5994 - val_acc: 0.8663\n",
      "Epoch 776/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1530 - acc: 0.9282 - val_loss: 0.6145 - val_acc: 0.8702\n",
      "Epoch 777/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1536 - acc: 0.9271 - val_loss: 0.5939 - val_acc: 0.8649\n",
      "Epoch 778/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1499 - acc: 0.9295 - val_loss: 0.5773 - val_acc: 0.8685\n",
      "Epoch 779/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1526 - acc: 0.9281 - val_loss: 0.5894 - val_acc: 0.8616\n",
      "Epoch 780/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1553 - acc: 0.9267 - val_loss: 0.6004 - val_acc: 0.8713\n",
      "Epoch 781/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1535 - acc: 0.9270 - val_loss: 0.5669 - val_acc: 0.8665\n",
      "Epoch 782/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1494 - acc: 0.9308 - val_loss: 0.5734 - val_acc: 0.8731\n",
      "Epoch 783/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1548 - acc: 0.9267 - val_loss: 0.5650 - val_acc: 0.8692\n",
      "Epoch 784/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1575 - acc: 0.9244 - val_loss: 0.6177 - val_acc: 0.8708\n",
      "Epoch 785/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1545 - acc: 0.9256 - val_loss: 0.5986 - val_acc: 0.8691\n",
      "Epoch 786/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1549 - acc: 0.9255 - val_loss: 0.5806 - val_acc: 0.8674\n",
      "Epoch 787/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1623 - acc: 0.9215 - val_loss: 0.5559 - val_acc: 0.8653\n",
      "Epoch 788/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1564 - acc: 0.9246 - val_loss: 0.6208 - val_acc: 0.8655\n",
      "Epoch 789/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1578 - acc: 0.9244 - val_loss: 0.5946 - val_acc: 0.8658\n",
      "Epoch 790/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1548 - acc: 0.9262 - val_loss: 0.5928 - val_acc: 0.8675\n",
      "Epoch 791/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1583 - acc: 0.9248 - val_loss: 0.5734 - val_acc: 0.8661\n",
      "Epoch 792/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1572 - acc: 0.9246 - val_loss: 0.5830 - val_acc: 0.8663\n",
      "Epoch 793/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1552 - acc: 0.9254 - val_loss: 0.6160 - val_acc: 0.8696\n",
      "Epoch 794/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1525 - acc: 0.9280 - val_loss: 0.6158 - val_acc: 0.8687\n",
      "Epoch 795/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1546 - acc: 0.9271 - val_loss: 0.5777 - val_acc: 0.8664\n",
      "Epoch 796/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1500 - acc: 0.9299 - val_loss: 0.6479 - val_acc: 0.8688\n",
      "Epoch 797/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1472 - acc: 0.9314 - val_loss: 0.5854 - val_acc: 0.8682\n",
      "Epoch 798/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1549 - acc: 0.9274 - val_loss: 0.6191 - val_acc: 0.8660\n",
      "Epoch 799/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1537 - acc: 0.9269 - val_loss: 0.5815 - val_acc: 0.8680\n",
      "Epoch 800/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1534 - acc: 0.9275 - val_loss: 0.5587 - val_acc: 0.8712\n",
      "Epoch 801/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1526 - acc: 0.9277 - val_loss: 0.6302 - val_acc: 0.8697\n",
      "Epoch 802/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1523 - acc: 0.9287 - val_loss: 0.6167 - val_acc: 0.8656\n",
      "Epoch 803/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1474 - acc: 0.9320 - val_loss: 0.6231 - val_acc: 0.8681\n",
      "Epoch 804/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1485 - acc: 0.9304 - val_loss: 0.6623 - val_acc: 0.8684\n",
      "Epoch 805/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1483 - acc: 0.9306 - val_loss: 0.6906 - val_acc: 0.8665\n",
      "Epoch 806/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1548 - acc: 0.9264 - val_loss: 0.5817 - val_acc: 0.8662\n",
      "Epoch 807/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1524 - acc: 0.9284 - val_loss: 0.5698 - val_acc: 0.8707\n",
      "Epoch 808/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1500 - acc: 0.9298 - val_loss: 0.6215 - val_acc: 0.8680\n",
      "Epoch 809/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1490 - acc: 0.9305 - val_loss: 0.6141 - val_acc: 0.8661\n",
      "Epoch 810/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1522 - acc: 0.9279 - val_loss: 0.6528 - val_acc: 0.8652\n",
      "Epoch 811/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1467 - acc: 0.9326 - val_loss: 0.6867 - val_acc: 0.8686\n",
      "Epoch 812/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1533 - acc: 0.9275 - val_loss: 0.6176 - val_acc: 0.8677\n",
      "Epoch 813/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1511 - acc: 0.9291 - val_loss: 0.6344 - val_acc: 0.8664\n",
      "Epoch 814/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1519 - acc: 0.9292 - val_loss: 0.6734 - val_acc: 0.8654\n",
      "Epoch 815/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1537 - acc: 0.9277 - val_loss: 0.5895 - val_acc: 0.8679\n",
      "Epoch 816/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1554 - acc: 0.9256 - val_loss: 0.5969 - val_acc: 0.8657\n",
      "Epoch 817/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1525 - acc: 0.9285 - val_loss: 0.5871 - val_acc: 0.8686\n",
      "Epoch 818/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1488 - acc: 0.9309 - val_loss: 0.6598 - val_acc: 0.8683\n",
      "Epoch 819/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1472 - acc: 0.9311 - val_loss: 0.6610 - val_acc: 0.8667\n",
      "Epoch 820/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1524 - acc: 0.9285 - val_loss: 0.5945 - val_acc: 0.8680\n",
      "Epoch 821/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1520 - acc: 0.9268 - val_loss: 0.6375 - val_acc: 0.8690\n",
      "Epoch 822/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1521 - acc: 0.9276 - val_loss: 0.5845 - val_acc: 0.8705\n",
      "Epoch 823/1000\n",
      "11086/11086 [==============================] - 0s 31us/step - loss: 0.1560 - acc: 0.9253 - val_loss: 0.6003 - val_acc: 0.8718\n",
      "Epoch 824/1000\n",
      "11086/11086 [==============================] - 0s 31us/step - loss: 0.1518 - acc: 0.9284 - val_loss: 0.5934 - val_acc: 0.8667\n",
      "Epoch 825/1000\n",
      "11086/11086 [==============================] - 0s 30us/step - loss: 0.1545 - acc: 0.9267 - val_loss: 0.6016 - val_acc: 0.8723\n",
      "Epoch 826/1000\n",
      "11086/11086 [==============================] - 0s 35us/step - loss: 0.1567 - acc: 0.9246 - val_loss: 0.6112 - val_acc: 0.8687\n",
      "Epoch 827/1000\n",
      "11086/11086 [==============================] - 0s 32us/step - loss: 0.1523 - acc: 0.9289 - val_loss: 0.6366 - val_acc: 0.8685\n",
      "Epoch 828/1000\n",
      "11086/11086 [==============================] - 0s 36us/step - loss: 0.1483 - acc: 0.9302 - val_loss: 0.6442 - val_acc: 0.8647\n",
      "Epoch 829/1000\n",
      "11086/11086 [==============================] - 0s 37us/step - loss: 0.1539 - acc: 0.9257 - val_loss: 0.6085 - val_acc: 0.8683\n",
      "Epoch 830/1000\n",
      "11086/11086 [==============================] - 0s 30us/step - loss: 0.1566 - acc: 0.9265 - val_loss: 0.5751 - val_acc: 0.8696\n",
      "Epoch 831/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1546 - acc: 0.9263 - val_loss: 0.5722 - val_acc: 0.8689\n",
      "Epoch 832/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1552 - acc: 0.9264 - val_loss: 0.5789 - val_acc: 0.8687\n",
      "Epoch 833/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1544 - acc: 0.9274 - val_loss: 0.5670 - val_acc: 0.8659\n",
      "Epoch 834/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1525 - acc: 0.9288 - val_loss: 0.6403 - val_acc: 0.8684\n",
      "Epoch 835/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1536 - acc: 0.9283 - val_loss: 0.6557 - val_acc: 0.8690\n",
      "Epoch 836/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1520 - acc: 0.9284 - val_loss: 0.6382 - val_acc: 0.8658\n",
      "Epoch 837/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1539 - acc: 0.9262 - val_loss: 0.5855 - val_acc: 0.8621\n",
      "Epoch 838/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1496 - acc: 0.9300 - val_loss: 0.6449 - val_acc: 0.8694\n",
      "Epoch 839/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1495 - acc: 0.9308 - val_loss: 0.6112 - val_acc: 0.8681\n",
      "Epoch 840/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1472 - acc: 0.9312 - val_loss: 0.6224 - val_acc: 0.8656\n",
      "Epoch 841/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1521 - acc: 0.9275 - val_loss: 0.6623 - val_acc: 0.8673\n",
      "Epoch 842/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1509 - acc: 0.9296 - val_loss: 0.6402 - val_acc: 0.8697\n",
      "Epoch 843/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1551 - acc: 0.9270 - val_loss: 0.5987 - val_acc: 0.8699\n",
      "Epoch 844/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1534 - acc: 0.9274 - val_loss: 0.6693 - val_acc: 0.8691\n",
      "Epoch 845/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1551 - acc: 0.9258 - val_loss: 0.6045 - val_acc: 0.8682\n",
      "Epoch 846/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1526 - acc: 0.9279 - val_loss: 0.6143 - val_acc: 0.8695\n",
      "Epoch 847/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1491 - acc: 0.9303 - val_loss: 0.6656 - val_acc: 0.8720\n",
      "Epoch 848/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1452 - acc: 0.9309 - val_loss: 0.6833 - val_acc: 0.8663\n",
      "Epoch 849/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1478 - acc: 0.9286 - val_loss: 0.6055 - val_acc: 0.8685\n",
      "Epoch 850/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1496 - acc: 0.9264 - val_loss: 0.6345 - val_acc: 0.8670\n",
      "Epoch 851/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1502 - acc: 0.9293 - val_loss: 0.6597 - val_acc: 0.8696\n",
      "Epoch 852/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1511 - acc: 0.9287 - val_loss: 0.6225 - val_acc: 0.8675\n",
      "Epoch 853/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1511 - acc: 0.9257 - val_loss: 0.6060 - val_acc: 0.8647\n",
      "Epoch 854/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1533 - acc: 0.9267 - val_loss: 0.6841 - val_acc: 0.8670\n",
      "Epoch 855/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1507 - acc: 0.9298 - val_loss: 0.6904 - val_acc: 0.8713\n",
      "Epoch 856/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1442 - acc: 0.9326 - val_loss: 0.6942 - val_acc: 0.8678\n",
      "Epoch 857/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1442 - acc: 0.9333 - val_loss: 0.6680 - val_acc: 0.8675\n",
      "Epoch 858/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1459 - acc: 0.9329 - val_loss: 0.6219 - val_acc: 0.8626\n",
      "Epoch 859/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1511 - acc: 0.9287 - val_loss: 0.6829 - val_acc: 0.8607\n",
      "Epoch 860/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1521 - acc: 0.9284 - val_loss: 0.6521 - val_acc: 0.8718\n",
      "Epoch 861/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1556 - acc: 0.9272 - val_loss: 0.6387 - val_acc: 0.8687\n",
      "Epoch 862/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1522 - acc: 0.9288 - val_loss: 0.6385 - val_acc: 0.8692\n",
      "Epoch 863/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1488 - acc: 0.9311 - val_loss: 0.6532 - val_acc: 0.8712\n",
      "Epoch 864/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1497 - acc: 0.9294 - val_loss: 0.6567 - val_acc: 0.8691\n",
      "Epoch 865/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1462 - acc: 0.9323 - val_loss: 0.6980 - val_acc: 0.8653\n",
      "Epoch 866/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1478 - acc: 0.9301 - val_loss: 0.6788 - val_acc: 0.8667\n",
      "Epoch 867/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1515 - acc: 0.9259 - val_loss: 0.6496 - val_acc: 0.8674\n",
      "Epoch 868/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1472 - acc: 0.9293 - val_loss: 0.6476 - val_acc: 0.8659\n",
      "Epoch 869/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1512 - acc: 0.9256 - val_loss: 0.6739 - val_acc: 0.8726\n",
      "Epoch 870/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1496 - acc: 0.9275 - val_loss: 0.6678 - val_acc: 0.8663\n",
      "Epoch 871/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1577 - acc: 0.9220 - val_loss: 0.5787 - val_acc: 0.8648\n",
      "Epoch 872/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1554 - acc: 0.9247 - val_loss: 0.6211 - val_acc: 0.8675\n",
      "Epoch 873/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1595 - acc: 0.9234 - val_loss: 0.5721 - val_acc: 0.8679\n",
      "Epoch 874/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1597 - acc: 0.9221 - val_loss: 0.5990 - val_acc: 0.8676\n",
      "Epoch 875/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1550 - acc: 0.9256 - val_loss: 0.5896 - val_acc: 0.8688\n",
      "Epoch 876/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1523 - acc: 0.9273 - val_loss: 0.5736 - val_acc: 0.8681\n",
      "Epoch 877/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1532 - acc: 0.9264 - val_loss: 0.5841 - val_acc: 0.8685\n",
      "Epoch 878/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1533 - acc: 0.9271 - val_loss: 0.6393 - val_acc: 0.8678\n",
      "Epoch 879/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1526 - acc: 0.9271 - val_loss: 0.6218 - val_acc: 0.8674\n",
      "Epoch 880/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1538 - acc: 0.9262 - val_loss: 0.6775 - val_acc: 0.8651\n",
      "Epoch 881/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1504 - acc: 0.9295 - val_loss: 0.6534 - val_acc: 0.8669\n",
      "Epoch 882/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1546 - acc: 0.9263 - val_loss: 0.5965 - val_acc: 0.8675\n",
      "Epoch 883/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1551 - acc: 0.9255 - val_loss: 0.6001 - val_acc: 0.8675\n",
      "Epoch 884/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1486 - acc: 0.9302 - val_loss: 0.6067 - val_acc: 0.8736\n",
      "Epoch 885/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1551 - acc: 0.9264 - val_loss: 0.6014 - val_acc: 0.8721\n",
      "Epoch 886/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1545 - acc: 0.9254 - val_loss: 0.5987 - val_acc: 0.8679\n",
      "Epoch 887/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1518 - acc: 0.9282 - val_loss: 0.6506 - val_acc: 0.8681\n",
      "Epoch 888/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1519 - acc: 0.9282 - val_loss: 0.6237 - val_acc: 0.8669\n",
      "Epoch 889/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1548 - acc: 0.9258 - val_loss: 0.6234 - val_acc: 0.8711\n",
      "Epoch 890/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1510 - acc: 0.9291 - val_loss: 0.6130 - val_acc: 0.8714\n",
      "Epoch 891/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1538 - acc: 0.9273 - val_loss: 0.6121 - val_acc: 0.8682\n",
      "Epoch 892/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1491 - acc: 0.9298 - val_loss: 0.6352 - val_acc: 0.8714\n",
      "Epoch 893/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1465 - acc: 0.9317 - val_loss: 0.6223 - val_acc: 0.8676\n",
      "Epoch 894/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1517 - acc: 0.9277 - val_loss: 0.6193 - val_acc: 0.8706\n",
      "Epoch 895/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1557 - acc: 0.9243 - val_loss: 0.5599 - val_acc: 0.8707\n",
      "Epoch 896/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1561 - acc: 0.9244 - val_loss: 0.6091 - val_acc: 0.8659\n",
      "Epoch 897/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1528 - acc: 0.9260 - val_loss: 0.6467 - val_acc: 0.8655\n",
      "Epoch 898/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1549 - acc: 0.9252 - val_loss: 0.6097 - val_acc: 0.8683\n",
      "Epoch 899/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1527 - acc: 0.9269 - val_loss: 0.6505 - val_acc: 0.8674\n",
      "Epoch 900/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1526 - acc: 0.9275 - val_loss: 0.5844 - val_acc: 0.8671\n",
      "Epoch 901/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1560 - acc: 0.9253 - val_loss: 0.6441 - val_acc: 0.8698\n",
      "Epoch 902/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1520 - acc: 0.9265 - val_loss: 0.6274 - val_acc: 0.8684\n",
      "Epoch 903/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1519 - acc: 0.9274 - val_loss: 0.6465 - val_acc: 0.8677\n",
      "Epoch 904/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1490 - acc: 0.9294 - val_loss: 0.6257 - val_acc: 0.8661\n",
      "Epoch 905/1000\n",
      "11086/11086 [==============================] - 0s 25us/step - loss: 0.1481 - acc: 0.9311 - val_loss: 0.6399 - val_acc: 0.8679\n",
      "Epoch 906/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1539 - acc: 0.9271 - val_loss: 0.6073 - val_acc: 0.8653\n",
      "Epoch 907/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1524 - acc: 0.9281 - val_loss: 0.5730 - val_acc: 0.8693\n",
      "Epoch 908/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1582 - acc: 0.9249 - val_loss: 0.6078 - val_acc: 0.8662\n",
      "Epoch 909/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1516 - acc: 0.9276 - val_loss: 0.6317 - val_acc: 0.8723\n",
      "Epoch 910/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1506 - acc: 0.9280 - val_loss: 0.5834 - val_acc: 0.8715\n",
      "Epoch 911/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1514 - acc: 0.9282 - val_loss: 0.6440 - val_acc: 0.8683\n",
      "Epoch 912/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1513 - acc: 0.9281 - val_loss: 0.6197 - val_acc: 0.8644\n",
      "Epoch 913/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1509 - acc: 0.9281 - val_loss: 0.6568 - val_acc: 0.8688\n",
      "Epoch 914/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1522 - acc: 0.9282 - val_loss: 0.6733 - val_acc: 0.8651\n",
      "Epoch 915/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1536 - acc: 0.9266 - val_loss: 0.6397 - val_acc: 0.8657\n",
      "Epoch 916/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1522 - acc: 0.9272 - val_loss: 0.6014 - val_acc: 0.8683\n",
      "Epoch 917/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1595 - acc: 0.9222 - val_loss: 0.6464 - val_acc: 0.8655\n",
      "Epoch 918/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1534 - acc: 0.9261 - val_loss: 0.6410 - val_acc: 0.8647\n",
      "Epoch 919/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1541 - acc: 0.9255 - val_loss: 0.6337 - val_acc: 0.8668\n",
      "Epoch 920/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1544 - acc: 0.9257 - val_loss: 0.6533 - val_acc: 0.8669\n",
      "Epoch 921/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1514 - acc: 0.9272 - val_loss: 0.6368 - val_acc: 0.8670\n",
      "Epoch 922/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1519 - acc: 0.9272 - val_loss: 0.6007 - val_acc: 0.8698\n",
      "Epoch 923/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1561 - acc: 0.9246 - val_loss: 0.6219 - val_acc: 0.8678\n",
      "Epoch 924/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1491 - acc: 0.9290 - val_loss: 0.6599 - val_acc: 0.8688\n",
      "Epoch 925/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1480 - acc: 0.9298 - val_loss: 0.6867 - val_acc: 0.8711\n",
      "Epoch 926/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1453 - acc: 0.9326 - val_loss: 0.7045 - val_acc: 0.8658\n",
      "Epoch 927/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1477 - acc: 0.9313 - val_loss: 0.6890 - val_acc: 0.8651\n",
      "Epoch 928/1000\n",
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1466 - acc: 0.9322 - val_loss: 0.7137 - val_acc: 0.8678\n",
      "Epoch 929/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 24us/step - loss: 0.1540 - acc: 0.9264 - val_loss: 0.6522 - val_acc: 0.8649\n",
      "Epoch 930/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1509 - acc: 0.9289 - val_loss: 0.6373 - val_acc: 0.8665\n",
      "Epoch 931/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1496 - acc: 0.9291 - val_loss: 0.6206 - val_acc: 0.8639\n",
      "Epoch 932/1000\n",
      "11086/11086 [==============================] - 0s 23us/step - loss: 0.1532 - acc: 0.9273 - val_loss: 0.6117 - val_acc: 0.8633\n",
      "Epoch 933/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1507 - acc: 0.9286 - val_loss: 0.6295 - val_acc: 0.8637\n",
      "Epoch 934/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1474 - acc: 0.9310 - val_loss: 0.6908 - val_acc: 0.8702\n",
      "Epoch 935/1000\n",
      "11086/11086 [==============================] - 0s 29us/step - loss: 0.1477 - acc: 0.9312 - val_loss: 0.6590 - val_acc: 0.8689\n",
      "Epoch 936/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1529 - acc: 0.9280 - val_loss: 0.6541 - val_acc: 0.8661\n",
      "Epoch 937/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1463 - acc: 0.9321 - val_loss: 0.6486 - val_acc: 0.8639\n",
      "Epoch 938/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1485 - acc: 0.9305 - val_loss: 0.6416 - val_acc: 0.8648\n",
      "Epoch 939/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1540 - acc: 0.9273 - val_loss: 0.6616 - val_acc: 0.8662\n",
      "Epoch 940/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1465 - acc: 0.9326 - val_loss: 0.7150 - val_acc: 0.8691\n",
      "Epoch 941/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1481 - acc: 0.9313 - val_loss: 0.7135 - val_acc: 0.8669\n",
      "Epoch 942/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1500 - acc: 0.9296 - val_loss: 0.5968 - val_acc: 0.8682\n",
      "Epoch 943/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1494 - acc: 0.9304 - val_loss: 0.6794 - val_acc: 0.8637\n",
      "Epoch 944/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1472 - acc: 0.9304 - val_loss: 0.7329 - val_acc: 0.8683\n",
      "Epoch 945/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1442 - acc: 0.9334 - val_loss: 0.7119 - val_acc: 0.8653\n",
      "Epoch 946/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1453 - acc: 0.9330 - val_loss: 0.7048 - val_acc: 0.8659\n",
      "Epoch 947/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1475 - acc: 0.9323 - val_loss: 0.6854 - val_acc: 0.8659\n",
      "Epoch 948/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1470 - acc: 0.9313 - val_loss: 0.6868 - val_acc: 0.8677\n",
      "Epoch 949/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1500 - acc: 0.9290 - val_loss: 0.6572 - val_acc: 0.8649\n",
      "Epoch 950/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1527 - acc: 0.9274 - val_loss: 0.6363 - val_acc: 0.8660\n",
      "Epoch 951/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1506 - acc: 0.9288 - val_loss: 0.6352 - val_acc: 0.8666\n",
      "Epoch 952/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1469 - acc: 0.9311 - val_loss: 0.6595 - val_acc: 0.8689\n",
      "Epoch 953/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1480 - acc: 0.9312 - val_loss: 0.7016 - val_acc: 0.8682\n",
      "Epoch 954/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1504 - acc: 0.9286 - val_loss: 0.6200 - val_acc: 0.8664\n",
      "Epoch 955/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1489 - acc: 0.9303 - val_loss: 0.6742 - val_acc: 0.8690\n",
      "Epoch 956/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1497 - acc: 0.9292 - val_loss: 0.6858 - val_acc: 0.8698\n",
      "Epoch 957/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1486 - acc: 0.9306 - val_loss: 0.6628 - val_acc: 0.8648\n",
      "Epoch 958/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1497 - acc: 0.9290 - val_loss: 0.6600 - val_acc: 0.8648\n",
      "Epoch 959/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1500 - acc: 0.9295 - val_loss: 0.6351 - val_acc: 0.8677\n",
      "Epoch 960/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1558 - acc: 0.9251 - val_loss: 0.5923 - val_acc: 0.8671\n",
      "Epoch 961/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1512 - acc: 0.9280 - val_loss: 0.5960 - val_acc: 0.8638\n",
      "Epoch 962/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1467 - acc: 0.9315 - val_loss: 0.6842 - val_acc: 0.8655\n",
      "Epoch 963/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1474 - acc: 0.9311 - val_loss: 0.6612 - val_acc: 0.8652\n",
      "Epoch 964/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1513 - acc: 0.9280 - val_loss: 0.6945 - val_acc: 0.8663\n",
      "Epoch 965/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1433 - acc: 0.9332 - val_loss: 0.6873 - val_acc: 0.8643\n",
      "Epoch 966/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1417 - acc: 0.9346 - val_loss: 0.6323 - val_acc: 0.8736\n",
      "Epoch 967/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1515 - acc: 0.9283 - val_loss: 0.6614 - val_acc: 0.8684\n",
      "Epoch 968/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1504 - acc: 0.9298 - val_loss: 0.7383 - val_acc: 0.8703\n",
      "Epoch 969/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1445 - acc: 0.9324 - val_loss: 0.6878 - val_acc: 0.8718\n",
      "Epoch 970/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1507 - acc: 0.9295 - val_loss: 0.6929 - val_acc: 0.8692\n",
      "Epoch 971/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1471 - acc: 0.9311 - val_loss: 0.7194 - val_acc: 0.8665\n",
      "Epoch 972/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1462 - acc: 0.9312 - val_loss: 0.6561 - val_acc: 0.8656\n",
      "Epoch 973/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1448 - acc: 0.9329 - val_loss: 0.7477 - val_acc: 0.8676\n",
      "Epoch 974/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1468 - acc: 0.9322 - val_loss: 0.6656 - val_acc: 0.8678\n",
      "Epoch 975/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1509 - acc: 0.9282 - val_loss: 0.6811 - val_acc: 0.8645\n",
      "Epoch 976/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1465 - acc: 0.9314 - val_loss: 0.7205 - val_acc: 0.8653\n",
      "Epoch 977/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1541 - acc: 0.9276 - val_loss: 0.6796 - val_acc: 0.8657\n",
      "Epoch 978/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1536 - acc: 0.9259 - val_loss: 0.6355 - val_acc: 0.8687\n",
      "Epoch 979/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1496 - acc: 0.9295 - val_loss: 0.6701 - val_acc: 0.8671\n",
      "Epoch 980/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1500 - acc: 0.9285 - val_loss: 0.7140 - val_acc: 0.8670\n",
      "Epoch 981/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1518 - acc: 0.9276 - val_loss: 0.6728 - val_acc: 0.8665\n",
      "Epoch 982/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1478 - acc: 0.9306 - val_loss: 0.7078 - val_acc: 0.8678\n",
      "Epoch 983/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1520 - acc: 0.9284 - val_loss: 0.6909 - val_acc: 0.8639\n",
      "Epoch 984/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1509 - acc: 0.9289 - val_loss: 0.6701 - val_acc: 0.8643\n",
      "Epoch 985/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1461 - acc: 0.9313 - val_loss: 0.7008 - val_acc: 0.8641\n",
      "Epoch 986/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1494 - acc: 0.9292 - val_loss: 0.6695 - val_acc: 0.8692\n",
      "Epoch 987/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1441 - acc: 0.9326 - val_loss: 0.6638 - val_acc: 0.8676\n",
      "Epoch 988/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1471 - acc: 0.9313 - val_loss: 0.7221 - val_acc: 0.8666\n",
      "Epoch 989/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1492 - acc: 0.9293 - val_loss: 0.6531 - val_acc: 0.8674\n",
      "Epoch 990/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1500 - acc: 0.9293 - val_loss: 0.7424 - val_acc: 0.8658\n",
      "Epoch 991/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1492 - acc: 0.9304 - val_loss: 0.6601 - val_acc: 0.8657\n",
      "Epoch 992/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1517 - acc: 0.9282 - val_loss: 0.7351 - val_acc: 0.8709\n",
      "Epoch 993/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1505 - acc: 0.9285 - val_loss: 0.6288 - val_acc: 0.8663\n",
      "Epoch 994/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1533 - acc: 0.9261 - val_loss: 0.6072 - val_acc: 0.8703\n",
      "Epoch 995/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1500 - acc: 0.9282 - val_loss: 0.6257 - val_acc: 0.8680\n",
      "Epoch 996/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1522 - acc: 0.9262 - val_loss: 0.6542 - val_acc: 0.8658\n",
      "Epoch 997/1000\n",
      "11086/11086 [==============================] - 0s 26us/step - loss: 0.1523 - acc: 0.9255 - val_loss: 0.6789 - val_acc: 0.8653\n",
      "Epoch 998/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1527 - acc: 0.9270 - val_loss: 0.6671 - val_acc: 0.8662\n",
      "Epoch 999/1000\n",
      "11086/11086 [==============================] - 0s 27us/step - loss: 0.1527 - acc: 0.9267 - val_loss: 0.6745 - val_acc: 0.8722\n",
      "Epoch 1000/1000\n",
      "11086/11086 [==============================] - 0s 28us/step - loss: 0.1491 - acc: 0.9301 - val_loss: 0.6662 - val_acc: 0.8718\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd4VGXa+PHvnUkjDUgIvQWlK01E7L2hYu+6dnRXd92fa2PX7u6+vru+1lVXXevau6ggiIodpAhI7yV0QkhISJ/n98c5M5lMzrSQySQz9+e6uGbmOc+ceQ4D556nizEGpZRSCiAp1gVQSinVemhQUEop5aVBQSmllJcGBaWUUl4aFJRSSnlpUFBKKeWlQUGpMInIyyLy1zDzrhORE/b1PEq1NA0KSimlvDQoKKWU8tKgoOKK3Wxzm4gsFJFyEXlBRLqIyBQR2SMi00Wko0/+8SKyWER2i8gMERnsc2ykiMyz3/c2kO73WaeLyHz7vT+KyLAmlvk6EVklIrtEZJKIdLfTRUQeFZHtIlJiX9MB9rFxIrLELtsmEbm1SX9hSvnRoKDi0bnAicAA4AxgCvBnoBPWv/k/AIjIAOBN4I9APjAZ+EREUkUkFfgI+C+QC7xrnxf7vaOAF4HrgTzgWWCSiKRFUlAROQ74H+ACoBuwHnjLPnwScJR9HR2AC4Ei+9gLwPXGmGzgAOCrSD5XqUA0KKh49KQxZpsxZhPwHTDLGPOLMaYK+BAYaee7EPjMGPOFMaYGeBhoBxwGjAVSgMeMMTXGmPeA2T6fcR3wrDFmljGmzhjzClBlvy8SlwIvGmPm2eWbCBwqIn2BGiAbGASIMWapMWaL/b4aYIiI5Bhjio0x8yL8XKUcaVBQ8Wibz/MKh9dZ9vPuWL/MATDGuIGNQA/72CbTcMXI9T7P+wB/spuOdovIbqCX/b5I+JehDKs20MMY8xXwL+ApYJuIPCciOXbWc4FxwHoR+UZEDo3wc5VypEFBJbLNWDd3wGrDx7qxbwK2AD3sNI/ePs83An8zxnTw+ZNhjHlzH8uQidUctQnAGPOEMeYgYChWM9JtdvpsY8yZQGesZq53IvxcpRxpUFCJ7B3gNBE5XkRSgD9hNQH9CPwE1AJ/EJFkETkHGOPz3ueBG0TkELtDOFNEThOR7AjL8AZwlYiMsPsj/o7V3LVORA62z58ClAOVQJ3d53GpiLS3m71Kgbp9+HtQykuDgkpYxpjlwGXAk8BOrE7pM4wx1caYauAc4EqgGKv/4QOf987B6lf4l318lZ030jJ8CdwNvI9VO9kPuMg+nIMVfIqxmpiKsPo9AC4H1olIKXCDfR1K7TPRTXaUUkp5aE1BKaWUlwYFpZRSXhoUlFJKeWlQUEop5ZUc6wJEqlOnTqZv376xLoZSSrUpc+fO3WmMyQ+Vr80Fhb59+zJnzpxYF0MppdoUEVkfOpc2HymllPKhQUEppZSXBgWllFJeba5PwUlNTQ2FhYVUVlbGuihRlZ6eTs+ePUlJSYl1UZRScSougkJhYSHZ2dn07duXhotaxg9jDEVFRRQWFlJQUBDr4iil4lRcNB9VVlaSl5cXtwEBQETIy8uL+9qQUiq24iIoAHEdEDwS4RqVUrEVN0FBKaXarJpKmP8GtIJVqzUoNIPdu3fz9NNPR/y+cePGsXv37iiUSCnVpnz1IHz0W1jxeaxLokGhOQQKCnV1wTfDmjx5Mh06dIhWsZRSbUXZduuxsrQ+raYS3rgIdq5q0aLExeijWLvzzjtZvXo1I0aMICUlhaysLLp168b8+fNZsmQJZ511Fhs3bqSyspKbb76ZCRMmAPVLdpSVlXHqqadyxBFH8OOPP9KjRw8+/vhj2rVrF+MrU0pF3aZ5ULy2cfq672DFFKirhss/aHw8SuIuKNz/yWKWbC4NnTECQ7rncO8ZQwMef+ihh1i0aBHz589nxowZnHbaaSxatMg7dPTFF18kNzeXiooKDj74YM4991zy8vIanGPlypW8+eabPP/881xwwQW8//77XHaZ7rCoVNx7/tjgxzf/0jLlsGnzURSMGTOmwVyCJ554guHDhzN27Fg2btzIypUrG72noKCAESNGAHDQQQexbt26liquUiqa6mpgyp31TUSRqtjVvOUJIe5qCsF+0beUzMxM7/MZM2Ywffp0fvrpJzIyMjjmmGMc5xqkpaV5n7tcLioqKlqkrEqpKFszA2Y9AyUb4aLXY12akLSm0Ayys7PZs2eP47GSkhI6duxIRkYGy5YtY+bMmS1cOqVUTCW5rMfqsjAy+w5Jjc28pLirKcRCXl4ehx9+OAcccADt2rWjS5cu3mOnnHIK//73vxk2bBgDBw5k7NixMSypUqrFJadbj7VVkb2vNjarF2hQaCZvvPGGY3paWhpTpkxxPObpN+jUqROLFi3ypt96663NXj6lVIy4Uq3HcG7y3z0Cwy4EEXj70vp0Y6y0FqDNR0opFU2eWcrh1BR2LoftSx3O4W7eMgWhQUEppZrT6q9hrz1iaOsieHW89Tzc5qDZz0ON30CTFgwK2nyklFLNpaoM/nsW9DkCrvrMmnxWs9c6VhNmUJjzIqRmNkxz14GrZfZR0ZqCUko1F88v/J0rrEdx1R8r3xH+eRZ92PB1vDQficgpIrJcRFaJyJ0Oxx8Vkfn2nxUioqvDKaXaLk8w8Pyq972Zu2vCP09pYcPX8dB8JCIu4CngRKAQmC0ik4wxSzx5jDH/zyf/74GR0SqPUkpF3cvjrEenoABQWQJrv4PBp0d23jipKYwBVhlj1hhjqoG3gDOD5L8YeDOK5Ymapi6dDfDYY4+xd+/eZi6RUioi25c2714GnmGo/jfz9662hpoWr4vsfCb4isvNKZpBoQew0ed1oZ3WiIj0AQqArwIcnyAic0Rkzo4dEbTLtRANCkq1QZ4gsHI6PD0WFjTjb9IkuxHG7Xcz37LQeqytth4rw1y8swU334nm6COnmRaBruwi4D1jnMOhMeY54DmA0aNHx35rIj++S2efeOKJdO7cmXfeeYeqqirOPvts7r//fsrLy7ngggsoLCykrq6Ou+++m23btrF582aOPfZYOnXqxNdffx3rS1EqMbjr4IFcOPYuSM+x0jbNhRGXNM/5PXMSnJqPACTJGqn0UK/wzhcPfQpYNQPfK+4JbA6Q9yLgxmb51Cl3wtZfm+VUXl0PhFMfCnjYd+nsadOm8d577/Hzzz9jjGH8+PF8++237Nixg+7du/PZZ58B1ppI7du355FHHuHrr7+mU6dOzVtmpeLdwnfgxyfhhu8if++2xdbjrGfguLut55EuQxHMrtVwX3vod0zD9Dr7M5JcUF0e/vnipE9hNtBfRApEJBXrxj/JP5OIDAQ6Aj9FsSwtZtq0aUybNo2RI0cyatQoli1bxsqVKznwwAOZPn06d9xxB9999x3t27ePdVGVats+uA62LoR138OSjyN7ryco5A+GZHuF4roIRgeFa80M5/SdK+oDRDj8m6GiKGo1BWNMrYjcBEwFXMCLxpjFIvIAMMcY4wkQFwNvGdNMjWZBftG3BGMMEydO5Prrr290bO7cuUyePJmJEydy0kkncc8998SghErFmZdPsx7vKwmdt6IYVkyFInuLy9JN4K61nkdykw4kJcOarCZJwX/dv3EBHH5z+OeNk+YjjDGTgcl+aff4vb4vmmVoCb5LZ5988sncfffdXHrppWRlZbFp0yZSUlKora0lNzeXyy67jKysLF5++eUG79XmI6VawPvXwqrp9c06xWth0u+t581RU/D2JYTxG/eHx8M/b7wEhUThu3T2qaeeyiWXXMKhhx4KQFZWFq+99hqrVq3itttuIykpiZSUFJ555hkAJkyYwKmnnkq3bt20o1mpaPPUEJxusr59Cut/gj1b4IBzwj93XW3woaOpWWHuqeDgsQPgqNvguLua9v4ISHO12rSU0aNHmzlz5jRIW7p0KYMHD45RiVpWIl2rUkHd59cvd9tqyAxR4354AJRtg4KjYe03DY9JEty6CjLz6s8dqknKGKu2kdvP6jj+e3fPyWg02DKrK5RtDX6+UO4phqSmdQWLyFxjzOhQ+XTtI6VUfPjnfqHzVNtzgjz9CL6MG146JbLPnP86PDES1v/oN3rJ4cd2WlZk53ayrZlHVjrQoKCUSgxf/RWq7W1z66qd83jWLgrXuh+sx11rQg9pTW2GoFBRvO/nCCFugkJbawZrikS4RqWi5tt/1j8PFBQi5dkjITk99OiltOzwzzvuYef0kk3hn6OJ4iIopKenU1RUFNc3TWMMRUVFpKenx7ooSrVexeudR/5sXdTwdbgjjULl8wSX5LT6pSsCiaSmMHCcc3puv/DP0URxMfqoZ8+eFBYW0hrXRWpO6enp9OzZM9bFUKr1enwYXPsV9DyoYfq/D2/4evsSwlJTEXxzG+9uahJ6Z7VI+hTaOywTd8m70OfQ8M/RRHERFFJSUigoKIh1MZRSrYFvu3tVGSz9pOnnqqmoXxvJiacfoa46dJNUpH0KWV2skVIeKS3TShAXQUEppbx85yBMud0aIdRUNSHWJ/IsP7FlPsx8xk50GI4K1mznQPqfDO06wMK3fRL91hRNbheisM0jLvoUlFLKy3cC2e4N+3auJR/Dmz4rp37+Z/jFJ8iIfeP+4XEo/Nl6nhagZpES5KZ+2O/hnOcapp37vN/7W6amoEFBKdV2bF9mTSzbvjRwHt85CPs6+GT6fbD8M+s8uzfAzKfg499Zu6cFkpXvnB7spp7scKzgKLj0PZ88WlNQSqmGlnxkPS7+MHAedy1snA2fTwx/x7KDrrIes7o6H6+thFd9No585XSoqYT1PzTOG+gcwZqPPCu1+hOfJiStKSil4sbfusMr45vvfMFqAO46eOEEmPl0+PMR8vaDEZdZ+xw4qamAMr/RjXNedM6b3cU53ak24BGoaUl8btFaU1BKxY2acmutoXC3nwzI88s5SFBY6rNtS7jzEVIzrTWF3HWw2mFX4NrKhr/aAaZOdD6Xb03htEfqnwerKQQa9uobFLSmoJSKOw/1gi0Lmv5+z405WE2hwYY7YfQp9DgIBp1RvwfCxp8b53nvaqgKM6D51hRGXlb/PNjQ1qQAA0HFp+aiNQWlVFxqju1yw71B1zksfOfvuLuszmFxWX0QTs08GyLYGNK3puB7s9//xMbbc3q4Uq3Hyz+Ca6bXp/vWFJq4OmqkdJ6CUqrt+fm50HkgvD4FT60jyWU1HwVr5glHtk9QaNAnkArH39twi87eh8LQcyCrs/V6v2Mbnkta/ne71hSUSgSb50dnD+ImEedkdx18fCNsC3MJinCE1dFsBwVxWQFiX9vuPTd4aNwP4d/s1aEPHDIh8Lk8NYgWpEFBqXi3fRk8d7Q15r41K1oFv7wG717R+Fhdrb3gXICAEkhNReg8nvu0JEFVCSQFWesoHO06hvFhtkCjnTxS97HW0gQaFJSKd+XbrcfN82Pz+W6/uQL+v549Au1D7HbDM4fBXwNMCgumZm/oPF0PtB737rQev3wg8s/xld4h8LFQQcDfvjZlNYEGBaXiXoS/rsOx8F1rZnFliO0qoXETzvw3YO+uxvmqA9zAH+gIO5dbz3/6V2TlDBUU7iupHy1UbgeFPZtDnzclM8ixIM1P3UbACffD2N9Zr/0Dpr/UIJ8TJRoUlEoYzbjfyPePWo/hrC3kvyPZuu/gw+sb5/PsimYMLPvMCjr+56/cHXlZwxVJp25Tm3VE4Ig/Qo69NHaoGddaU1BKxUQ4QzcdhVELcers3bOlcVpVWf3zef+1HrcsDPLRPk0xY28MXY5QIgkK+9rv4JmsFqjJzCPYInpREtWgICKniMhyEVklIncGyHOBiCwRkcUi8kY0y6OUcrBlITyYByumRvAmu9ZRVWqtARSM097Fvjf0LQvhq7/57B1g6n9BB7tR+84CDrYRTrgC9XUUHAUn+vUzhOob+MN8uGVZ4OOe8oZqPgpUpiiK2jwFEXEBTwEnAoXAbBGZZIxZ4pOnPzARONwYUywinZ3PppSKmo2zrMcVU2HAyZG996VTrY7aG74PnKd4XeO0LfOtG2LRKnj2SCstrb31WLXH52YZpMnLlVq/21mkHbgAXYf5JQS4AZdsgo5+m3iFqlXkhtj0y1PTcIdRQxtzPRQcGTpfM4nm5LUxwCpjzBoAEXkLOBPwHYR8HfCUMaYYwBizPYrlUSoxhfq16Rk7H0nzie94+1AzlOe94pxeUwGlPhvRV9md1uU76m+Wv7wW+Ly+s4UlgqBwxSfQaWDjZScCNeXsWt14GYqmBCFfnvkH4SztPe4f+/ZZEYpmUOgBbPR5XQgc4pdnAICI/AC4gPuMMZ/7n0hEJgATAHr37h2VwiqVsDw3w4iaKvxuZkWrrce8/RpndaopgNWs5HQjNm7YYY82Wj45cBF8yxvJTbrgKOf0YJ2+/kHBNwid+bT13gVvQ49R4ZXB26cQ5tLeLSiaQcHpX5h/WEwG+gPHAD2B70TkAGNMgyEGxpjngOcARo8e3YxDKJSKU8ZYC8MNHNcwzTGv58YcJCgs/RTevhRuXWnN2PU/15P2zfC+Eph+v/Vr/0x7+Gigoaa1lYFbh8q2Bi6Lk3AW2Tv3Beg8JPBxx/Z9gWunNx566xuEBp9h1TpG/SbIh/v93XpqZaE6mmMgmkGhEOjl87on4D8AuBCYaYypAdaKyHKsIDE7iuVSKv6t+dqaGXzY7639f4Px1hSCNB/NtreG3Por7H988PN9by8X7QkKgfY5rq3ct5uib2AKVBvxdeB5Ic7nFxRumgMd+1q/6td8E/h9gVY49ZhYSKOgUGa3lOcPCv7eGIjm6KPZQH8RKRCRVOAiYJJfno+AYwFEpBNWc9KaKJZJqcTg+WVbvN7nZudzE927C6rLG6YHCwqe5pKm3MQDLTWxez28cX7DtKBLRPjxLYv/vsieyWGRcPtdW6f+9c08/jd+34AUKiikZUNaVsO04RfCIb+Fo++IvJxRFrWgYIypBW4CpgJLgXeMMYtF5AER8WzBNBUoEpElwNfAbcaYomiVSamE4blRueucm0X+UWAtHQE+Hc1Bmo88zSXuOnhkaP0M43AEaj5a+knjtIri8M/rJXDufxom5Q+M/DSR9CkQQVBwkt4eTn2ocbBoBaK6dLYxZjIw2S/tHp/nBrjF/qOUai6eG5WpC/zr3tPk8sXd1mOwoOCtKdRBaWHgfD8/3/C1MYGbj1ZOd04Pm08Np0MvuGmutYfzVw9Ct+HWCB/PxLkxDjOo/QWbMxC0phBfc4Dj62qUUhbPTaxwNrxut6WHGv4YrPnIU1NYFmQ0EMDkW+ufVxQHHmEEUBJgiYywh5d6dmGzz99pfzjyT9akse4j6/8ORl8d3rDOoDUFu0yZneFPK/AGpCP/FGZZ2w4NCkrFI89NbG+I1tjP/1z/PJygMD/IvAF/n/0pvFVKA31WKGnZ9hOfYCcCOd2s557PXvZZeOcbfnGQMtkBJqWdtYCeJ8AOuyi8c7chGhSUikfB2rl9N9uZ+ZTPgTCajyKxt8inMzsCnrIfEGC00HF3WY/hriAaahkOj4OvDV0mb+AMox+mjdKgoFQ8cgwK9o0s0K/3oH0KTbhVpGZBdVnwPMGGZPY7unHayX+HfseFV6YOnomuYU5t8r3+i95seMxTe/Hk8QQmz2qncUSDglJxKcgNPtAQ0WDDTZuyrEO3EfB8iDkN/v0cv/m4vhyutIbHcnrAoTfWL1tdW2WlHfZ753N71mOqKg2/zHesgzs3wKBxATLYf68HnGtN1IvBzmjRpkFBqXgU7AYfqKbguzibMfDhDbDuh8g/29vUQuCRR97PcTdcTbTvkfWBItlvf2LP4nfJ9iY2ddVwyxI46a/O505vb9VEznzK+biTdh2t9zmVE+KyucifBgWlWqt3r4SXT4eyHZG3zTuuKeRpPgpQU/DdU6GmAha8CS+Ps9rkI1lW2zO0M5w9Goy7vmMYGtZIXGlwdxEcfrP12rMEtycoOC3J7e/GWTDystD5QpazCYsGtlHxf4VKtVWLP7R2KXt4f3jWoX3do7ocfnm9YVNM0JpCgKDQoKbgMzzztXMj3PHMND5fwKxOw0B9agquZDjqNuu1p6bg2e6yJZtuMnKtx/4ntdxnxkhUJ68ppZpJ0crAx6bcbi0xPeV2uGYatO8ZICiE6Gh218C8V2HS7xv+It48L3T5OvZtvP6Qu8Ypp1+eIDUaT5+CZ0vKrK7WY7uOcMpDke/9sC+yOsMtSyGrS8t9ZoxoTUGptqKu1nkCmmcf4+oya+mK549vWk2hrha+/h/rue/7Q/3iP+hKyO7eOH3DLGtW8RH/L/B7ncrpCSaeIadJLjj/ZbjaZ1X9sb+F3H7By9Xccrrv+z4KbYAGBaXaigfz4PtHG6f7t90XrQxws7XzBaopLHwb9vgvZIzzHsuN8ji072+cab3Xdz/jc1+As5+tf+0p54WvN54d7DsPYejZ1lIWKuo0KCjVlvz6buM0p5v2sk8bp23+BUoKYfLtjY91LAivuceJMcEDh++ciYHjYLjPLGBPn8Lg0+H4exq+L9zJaapZaVBQqjUKtE5RRl7jNKebeflO5/c/OhTK/Xa9zcyH5DTn/GExDWdJ+3P5BAVP88v59hadwZq5NCjEhAYFpVqjQMMt/fcbcNc57zoWyb4Ht65s2vLPvoIND3XaS9m7HWWQcqZoUIgFDQpKtUaB5iWktKt/XrYdpt3tnK82zPV+wJqQ1ZSgMOoK69GYELOhfYOCfctJCiMo+E9eUy1Cg4JSrVH1ngAH7Bm1q76Eh/v7LWjnY/VXwc9/t1/zUjhBoUOfhq97HFT//JK34eDrrOftezfM59vR7Nl7wNOk5DQk9cynoN8xocujokKDglKxtmGWtcy0px+hdAtUBVhIzrPMQuG+bGPuUDMIp7mp4MgABwx0HgynPQy3r204dBSch3F6awoOk9dGXmatgaRiQievKRVrH90Au9ZY+wpXl8OzR8KIEEsz7MuG98lpjdfwCWffg7IdDV87rQPkmfnry5VirUG0w2eNI5fdNLQv16GiQmsKSsVae3v8/fal1rIWYI3xD2ZfbqZO/Q3hrK3ku3/yb3/yKYtD3vNfhjR7YbmkZLhqClz3df1xb/NRkN3OVExoUFAq1lLtzdury615BABFq5zzLngTvnvEecjqvozWiWTBvaPvhC5DCLo899Cz65ehEJdVg+gxqv54OB3NKiY0KCgVa55RNh9OgD1bQuf/8n7nm+nJf2t6GUI1H132Qf1n+t7cgYCb2Hj6LZzKGs6QVBUTGhSUijWXz9DLxR+G+SaHG/Hoq5yzHn1n6NOFGsKa2am+U9hzs+97uPU47ELn93hGGjmtnRSso1nFlHY0K9WSNs6GD66F67+D9BwrzdWE8fjhtsXfvMBawfSbhxof+/08ax/lcGTm13+m51d+bj9r97FAPMHDKSi49NbTWmlNQaloMwZmPgN7d8GMv1tLTG/8ed/OGWilU39Om8L0PNh6zNsPeo1xft+g0xu+zsjz2SYzzCDmbT5yCGC+cxdUqxLVoCAip4jIchFZJSKN6rAicqWI7BCR+fafa6NZHqViYvMv8Pmd8NHvfDqVy+DNS+Dn5+GX/0Z+Tt+RQME4BYWhZwfOn9be2vd4+MXW66s+h4vfsoaxeoJCuDd0z5IWTrUalwaF1ipqdTgRcQFPAScChcBsEZlkjFnil/VtY8xN0SqHUjHnaT7ZW2T9OgerQ3n5Z9afpgh38ppTUHCavZzcDmor4I61dh5X46Yhb/NRmLeNpCDDTvd1rSUVNdGsKYwBVhlj1hhjqoG3gDOj+HlKtVKeoZumvqbweRidv8HsXu+c/odf/D7a4b+400qrN82Gq6dZwSDQRjKR1hSy8q3HtKzGx5rSj6JaRDSDQg9go8/rQjvN37kislBE3hMRx100RGSCiMwRkTk7duxwyqJU7K39FjbPb5zuuTEbt/MNsjnl9oO/bPP98IbHT/obDD2n8fs69ILehwQ/t/HraA7l0Jvg9MdgxKWNj2nzUasVzaDgNLPFfxzdJ0BfY8wwYDrwitOJjDHPGWNGG2NG5+fnN3MxlWomr5wBzx3dON1bUTBQG8YuZvvKs7E9NK4pHHRl/VDRSHmagcLdktKVYg2TDbb2kWp1ohkUCgHfX/49gQZ7/RljiowxnoXYnwcOQql441kJ1LitdvuW5B8U9qUt39N8JM2wT3FTA5OKumh+M7OB/iJSICKpwEXAJN8MItLN5+V4YGkUy6NU9Gz+JfAxT0ezccOcFwPni8avZ/9F65ojKCTA5vWJLGpDAIwxtSJyEzAVcAEvGmMWi8gDwBxjzCTgDyIyHqgFdgFXRqs8SkVN1R547piGacbU35A922UG27ISrBt2U/dJDqRRTWEfbuie5iOnzuumOP1R6BWiH0O1uKjW4Ywxk40xA4wx+xlj/man3WMHBIwxE40xQ40xw40xxxpjlgU/o1KtUI3fEhG/vAb3d4DyImvlU88id6FmD4fT+XrD9zD+yfDL5rmBeza+cVruOlw9R1uPKRlNP4ev0VdDl6HNcy7VbHSwsFL7qs5vf+Jv/td6LN8OT4+tTy/fbj2e96JVk/j2Ydjh02Lq+RV/5lPw8Y3On9X1QEjLCb9snqBw7RewdVH473NyznOwcyW067Bv51Gtmvb2KNVUe3dZ22L61xR2b7AeAzUXZeTBgec1XmLC097ve9O/aS4cbE/092y8k5xO2DxBIbsr9D8h/Pc5Sc2E7iP27Ryq1dOaglJN8eOTMO0u6/k1Xzjn+fYfzumeyWO+y0bnD4ZKewaxKwVuWWo1N3Xa37qhA2R1th5TwggKkmSdv7na/1XC0H8xSjWFJyAAVJY651n6iXN6pn1z952289sf62sKScmQ091qKgKos0cvefockts1PufY3zV8nd09YNGVCkZrCkrtq22/RpbfW1PwSUtKql9TyH/YqGdIqyc9ORVO/jtM/bP12mn56qsmw5qvw6tVKOVDawpK7avp90WW33Pz9991zDNPwX8Ukjco+AwnPTRAR7RHxz7W7GWlIhRWUBCRm0UkRywviMg8ETkp2oVTqtW1oyKaAAAgAElEQVTZsw3WzGiec3kng/nVEPwnsXlqFt5mJ6WiJ9zmo6uNMY+LyMlAPnAV8BIwLWolUyqWyndCxW6ro9fXq+NhR3NNp7Hbj8b/y3r01AT8m4/G/s7aDnPYRc30uUoFFm7zkWfGyzjgJWPMApwXvFMqPjw5Cv51EPzLb9ho0arQ7x33cOO0G+39D1xp9WnetYTs/4beYOC3bqQrGUZc0ni9oDMeh3NfCF0epSIQbk1hrohMAwqAiSKSDbhDvEeptsszPHTncuvRGGvEkdN+w/7SshundegNZz4NnQfVpxn75u+ZZezpSwi1HIaH9hmoKAg3KFwDjADWGGP2ikguVhOSUomhbBv89K/Ax4ecZS2Kt3s9lG5ufDw5DUb67yvgCQp+NYVwAo9SURJu89GhwHJjzG4RuQy4C3AYB6dUG7ZqOswLsF9yZYh/7iMugQkzYPAZ1nN/TmsOeTqQPbuxjb7aeuzUP5zSKhUV4dYUngGGi8hw4HbgBeBVwGFHEaXaqNfOtR5/eLxh+q418N0jwd+bmgkZuXDha+F/3gn3QacBMOBk6/WB51l/lIqhcINCrTHGiMiZwOPGmBdE5IpoFqy5bSmpYEPRXkb3zcWVpH3kyrZnKyx4C35+vj6taGXDPE+MDH0e3w7kcKVmwpjrIn+fUlEUbvPRHhGZCFwOfCYiLqBN7ac3af5mLnxuJlW1dbEuimpN3r8Wpt8LpYX7dh6XLg6g4kO4QeFCoAprvsJWoAfwz6iVKgqS7DZdt/8u0Sqxle8MM2OI2mWwXdOOuCXs4igVa2EFBTsQvA60F5HTgUpjzKtRLVkz826CZTQqKB8m3JpjiH83rtSGr29fCwfbTUMpDgvYKdVKhbvMxQXAz8D5wAXALBFpUz1iYkcFjQmqAf/1h3wNOSv88/g3H2XkWn9CfYZSrUy4zUd/AQ42xlxhjPkNMAa4O3rFan6evmWjUSH+1VaD2w21VfDNP6GmInBed5CaQruODV/n+Sx50f8kuNVndrNT89GISyCrCwy/OLxyK9UKhNs7lmSM2e7zuog2tsKq9ikkkL/mN3xt3HDMHQ3T9myDN86H4rWBz3PSg9bWk98/ar0++zn4z3HW80vfbZjXv/kIoGNfuHVFREVXKtbCvbF/LiJTReRKEbkS+AyYHL1iNb8k7VNIDHUOs4FnPg0bZllDT2c8ZKXNfw22LAh+rrRsOOSG+tfB9ib2X+5aqTYqrJqCMeY2ETkXOBxrGMZzxpgPo1qyZibemoIGhbhWW9k4rXI3vOiz0nu7XPjygfDO59kKE6y9kY+6HTr0apzPf2VTpdqosP8lG2PeB96PYlmiKkk7mhODU1Dw932I2cmBpLSD4/7ifMyp+UipNiho85GI7BGRUoc/e0QkwMa0Dd5/iogsF5FVInJnkHzniYgRkdFNuYhw6JDUBBGsU9ljz5amnTs5yNaW2nyk4kTQoGCMyTbG5Dj8yTbG5AR7rz3r+SngVGAIcLGIDHHIlw38AZjV9MsIrX70UTQ/RcVcbVXT33vm0/UrljoJFhR8t8pUqg2L5giiMcAqY8waY0w18BZwpkO+B4F/AGHU+5tO+xQSRG0YNYVABpwCB14Q+Lj/JjdKxaFo/ivvAWz0eV1op3mJyEiglzHm0yiWA9A+hYRR4/fbosdoyAtzKWpXirWbmb9+x+57uZRqI6I5ZMJpsRjvLVlEkoBHgStDnkhkAjABoHfv3k0qjA5JTQBbFsCX9zdMS29vbXDjv/Kpk+Q064+/S94JXAOZ8A1smht5WZVqpaIZFAoB37F7PQHfLamygQOAGXbTTldgkoiMN8bM8T2RMeY54DmA0aNHN+murpPX4lxFMTx/PLj9trIUCT5r+fKP7F3Vngo8gig51frjpPsI649ScSKaQWE20F9ECoBNwEWAd0sqY0wJ0MnzWkRmALf6B4TmoqOP4lBtNUy53Zo5PP1e5zySFHx7y/3spqHhFzV78ZRqi6IWFIwxtSJyEzAVcAEvGmMWi8gDwBxjzKRofbaT+gXxNCjEjZVTYe5LITKJ7nmsVASiOg3TGDMZv+UwjDH3BMh7TDTLokNS27DyIijdBN2G1aftWgtVZaHf69R85EqD0x+BnO7NW06l4kDCzM3XPoU27PljYPcGuK/Eem0MPBGkHb/7KMjMt2oS+QOtpSq2/WodO/5eGDgOOg8K/P5z/gNZnZut+Eq1JQkUFKxH7VNog3ZvsB5/ehoOuR5q9gbP3/VAGP8ErPkG+hxmrZI692Xr2CHXW3sjBzPs/H0uslJtVcIEBZ28FgemToQdy2DeK4HzHHQlnHCf9bzf0fXpXQ6AbYuspiOlVEAJExR08lqcCBQQTnnIqkEc+Sfn45d/ZDUh+e+QppRqIGH+h3hm0mlNIU6N/W3w41n5kHVcy5RFqTYsYRZz8SxbozGhjdm2JHSePy6KfjmUShAJExS0T6GV27oI5r/RMK2mEp45tHHeu7Y3fO206Y1SqkkSJijokNRW7t+Hw0e/hf8tgF/fg7oaeNVhUd2kZOf1iZRSzSJh+hTqJ69pVGjVKnZZS1cseh82zmx4LDkdbl8Tm3IplSC0pqBan71FsHxy4/S07NBzDJRS+yRhgoIuiBcHknwqtr+L6kZ9SiWshGk+ErSjudXa+HPw4/mDrElr4rPlZedB0OMgSMmIbtmUSjAJExQ8fQpoTGh9fn3POb3TADjtEWujnGePtPobfF33VfTLplSCSZygkKR9Cq2Suw5+ftb52IWvWQva1dkb5+Tu13LlUipBJU5Q0D6F1sNdB1WlkN4B/n2Ec57+J1kBAay9k6/5Ajr0abkyKpWgEiYo6OS1VuSrv8L3j0C3EbDdYcbysAvh6DsapvUa0zJlUyrBJUxQ0AXxYuinp2HPZuh9KCybbO1zALBlfuO8E77RPY+ViqGECQq6IF4MTZ1oPf74ZOi8GhCUiqmEmaegNQWllAotYYKCTl6LkZLCwMe6DoOsri1XFqVUSAnTfKTLXMRAbRUs/TTw8asmW0tXuN2wdgZkd2+xoimlnCVOUPDup6BRocW8dzUsCxAUJMkKCGB9OfvpBjhKtQYJ03ykNYUWVlsVOCAAGHfLlUUpFbYECgrWo/YpRFl1OezeCH/t3DD9iFsavnaltlyZlFJhi2pQEJFTRGS5iKwSkTsdjt8gIr+KyHwR+V5EhkSxLIAGhah7+TR47ICGaUfcAifcC7etht/+aKW5dKMcpVqjqPUpiIgLeAo4ESgEZovIJGOM7xTWN4wx/7bzjwceAU6JRnlS7E6FmjoNCs2uthqePgTG/g42/1Kfntcfhp4Fx91lvc7shHfGSJ6uY6RUaxTNjuYxwCpjzBoAEXkLOBPwBgVjTKlP/kyiuIZparInKGhbdrPashCWfgK71sDkW+vTh54D57/UOH9mHpz1jHYsK9VKRTMo9AA2+rwuBA7xzyQiNwK3AKmA451CRCYAEwB69+7dpMKkuKxfqBoUmtmzRzqnB5uZPOKS6JRFKbXPotmnIA5pjWoCxpinjDH7AXcAdzmdyBjznDFmtDFmdH5+fpMKk2LXFKprNSg0m5fGBTno9PUrpVq7aAaFQqCXz+uewOYg+d8CzopWYVJddlDQmkLz2LMN1v/gfKznGBh+ccuWRynVLKIZFGYD/UWkQERSgYuASb4ZRKS/z8vTgJXRKkyKHRRqarWjOWJut7W6qdsnoFbuDpz/2i8gq2k1OqVUbEWtT8EYUysiNwFTARfwojFmsYg8AMwxxkwCbhKRE4AaoBi4IlrlcSUJSaJ9Ck2y4E34+HdwyG+heg+kZDbcLW3MBBh5Gbx+PuToUhVKtWVRXebCGDMZmOyXdo/P85uj+fn+UpOTNCg0RYk9XmDWM42PjfoNjPun9fyWZS1XJqVUVCTM2kdgNSFpn0KEZj0HM/4n8PHR19Q/T0qYCfJKxa2ECgqpriQdfRSpn59zTh94GhQcCd2Gt2x5lFJRlVBBIcWlzUchrZlhzVCu2QvrvoP2PaHIof9/xMUw+IwWL55SKroSKygkiy5zEcqrZwY/fuxdMPaG+mWvlVJxJaGCQmZqMmVVtbEuRutUUwlVpYGPn/RXOPhaSE6v38ZOKRV3Eioo5GWlsqu8OtbFaH2MgfevCb7/wWG/b7nyKKViJqGGi+RlplFUVhXrYrQexeugeL2194FTQDjubuvxqNtatFhKqdhJuJpCUZnWFFj/kzXMdO03DdOT0+G8F2HguPomoqNubfx+pVTcSqig0CkrjT1VtVTW1JGe4op1cWLjm3/C1391Pvb7udZoI6VUwkqooJCXaW0Buau8mu4d2sW4NC2gpgL2FgECtZXWiCHfgJCZD/ufAPmDYMcyyNYlKpRKdIkVFLKsLSCLyhIkKEz9M8x5sXF6cjvoPhJOfUgnnymlGkiooNA7NwOARZtLOLBn+xiXpgVsnt84rf/JcOk7LV8WpVSbkFCjjwZ0yaJvXgafLgy2rUMbtmGWNd9gwVtwX3vYPM9K7zkGjv0LDD3beYtMpZSyJVRNQUQ4Y3h3nvp6FSu37aF/lziZlTvrOVj8IWz40fn4tV+0bHmUUm1W4tQUSjbB6q+5+OBe5GamccWLP7N4c0msSxWZvbvAXWdNNnO74fM/ww+Pw5TbnAPCAefCtV+2fDmVUm1W4tQUfn0Xpt9L9z9v5j9XjObCZ3/itCe+Z1TvDlx6SB+OGpBPfnZarEtZr2QTTL4VTn8Mdq6AV04Pnr9jX9jvODBuOPFBSM9pkWIqpeJL4gSFdh2tx727GNGrF9/cdizPfrua9+YU8qd3F5CcJIw7sBtnj+rB0f3zSUqK8vo+tdVQUQzLJ0PefuBKs/oAFr4NdbWw7Vcr3/LJwc8DMOoKGP9EdMurlEoIiRMUMnKtx4pi6NCLru3TufeModxz+hA+WbiF579dw5RFW5i0wOqE3r9zFkf1z6d/lywGdc1mcLec0BPe3HVQugnW/WAFoeoyKN8BRath9vNQcDSUbnZeijqUoWdb/QYDToXj7oIOva15BxXF9demlFL7KHGCgqemsPQTa9LW+h+gohgZdQXjh3Vj/PDurN66i0/nrGbb9u2k7VnMZzM7ku0uJY891JLE4T2SyHMX0T4tibHJy8nIziVj2xyScUPxWnCHWIG1qjR4QDjkBug8BHodArkFkJQCm+bC6q+s9YfOf9kKPEk+wUkDglKqGYkxbWt/gdGjR5s5c+ZE/sbtS+Hpsc7HUjKsTWX2UWlSBzLcZdQlpbAlZxhru51GbU0NewtOpE+vXnTvmEGyCB0qNpDUoRekpO/zZyqlVDhEZK4xZnSofIlTU+g00OqA3bbIWhm0bBskJUNymrXMQ02F9Uu/39HgSoWy7VbTTPeRVs0iyQUpGRSZLEprkiipMvy6y8WWcjc791RTUlHD+uJKKmrqKK+qY+fWKthqf/aiQqDQW5TstGRgDZ2y08hpl8LALllU1brpk5vBfp2zyExNZlSfjuTay3IopVRLSZyaQgvbVV5NskuoqK5j1fYytpVWsnJ7GTnpKazbWU6dMVTW1LGlpJKFhbvpmJHK9j0Nl/XOSHWRkZpMu9QkDujenoP75pKe4mJMQS77d86K0ZUppdoirSnEmOdXfk56Cl1ygjcTGWMQEapr3cxaW8TMNUW4RFi9o5yKmjpmriliyqKtTFm01fuew/bLo12Ki+o6N+eO6slh++fROVubo5RS+0aDQisg9t4FqclJHNk/nyP75zc4XlvnpnhvDTV1br5atp1Fm0r4dVMJCwtLKKuq5buVOxGBgV2yKeiUyenDutM7N4NB3bJJcSXO/ESl1L6LalAQkVOAxwEX8B9jzEN+x28BrgVqgR3A1caY9dEsU1uU7EryTqy7bGwfb7oxhi0llcxcU8TizaWs3VnOT3atwqNTVioXHtyLAV2yOXpAPh0ytJ9CKRVY1PoURMQFrABOxOplnQ1cbIxZ4pPnWGCWMWaviPwWOMYYc2Gw87aVPoVY2VlWxbTF2wD48JdCZq8rbnC8b14GVxzWlyP7d6JvXibJWpNQKiGE26cQzaBwKHCfMeZk+/VEAGPM/wTIPxL4lzHm8GDn1aAQPrfbUFZdy/Kte7jjvYVs31NFanISu8rrtyTNSU9mbL88ThzShTEFufTJy4xhiZVS0dIaOpp7ABt9XhcChwTJfw0wxemAiEwAJgD07t27ucoX95KShJz0FA7um8tXtx4DQHWtmx9W7+S9uYV8vmgrA7tm89Wy7UxbYtUuRvXuwJ7KWk4f1p0uOWmcPaoHackJunWpUgkomjWF84GTjTHX2q8vB8YYY37vkPcy4CbgaGNMlf9xX1pTaH57Kmv419erePabNY7HLxvbm/vHH4BA9NeEUkpFRZtpPhKRE4AnsQLC9lDn1aAQXUu3lLJ7bw2z1+3ikS9WNDreo0M7zh7Zg9zMVC4d21trEUq1Ea0hKCRjdTQfD2zC6mi+xBiz2CfPSOA94BRjTFirxGlQaHkvfL+WBz9d4njs7JE9OHNEdw7brxMpLvEOr1VKtS4xDwp2IcYBj2ENSX3RGPM3EXkAmGOMmSQi04EDgS32WzYYY8YHO6cGhdipqXOzdEspReXVPDZ9JQs27m6Up1NWGv93wXD6dcqkl70ntlIq9lpFUIgGDQqtx9qd5dzz8SI2FVewZme5Y577xw+la/t0ThjcBZfdH1FT59ZJdUq1MA0KqkWVVtZQsreG12auZ2dZNe/PK3TMd/5BPflo/iZuP3kQKS6hd14Gxw3q0sKlVSrxaFBQMWWMYfueKl74fi2z1u5ybGryuOrwvkw8dTCfLNjMQX06Ury3mgN6tNfahFLNSIOCalUqa+ooLN7LF0u2s3pHGe/NLaRHh3Zs2l0R8D2z/3ICM9cUceh+eXy6YDPHD+5Cz47t2FNVS056Cmt3lrN0SymnDO2qQ2WVCkGDgmrVyqpqSU4SyqpqeWPWBj6ev4nVO5z7JXy1S3FRUVPXKL1PXgY56Sk8fekoenRo1yhIlFTUsGZHGSN7d+TdORsREc47qGezXY9SrZ0GBdXm1LkNy7fuYf/OWXz0yyben1fIok0llFc3DgKhtG+XwvBeHXj8whGkpSQx5J6pAHTISGH33hoAjh6Qz4lDurB4cylDumVz+aF9wzr3up3lbN5dwWH7d4q4XErFigYFFRfcbsPni7cytHsOW0oqWbOjnP3yM7nu1Tk8csEIhnTPYdrirbw6cz1rHGoaoZqofB09IJ9vVuwA4I8n9OePJwwA4OP5m9hbXcf+nbP4ZvkO3p9XyJaSShbcexLt26VQXF7N96t2UlPn5pxRWvsIR3F5Ncc/8g33njGEM0f0CJn/g3mFjO6TS+88HebcVBoUVEKqrKlj0oLNzFxTxAfzNnnTB3fL4c/jBnHzW/PZVV5N79wMNuwKvC+3CDx9ySj+8/1a5q4vdszj1JTVvX06T14yiqKyKv719Sp2763hyYtHkpaSxPqivWwvreSysX0QESpr6pi6eCunD+uOK0n4dsUO/vDWL7x53VgGd8sBYO76Yj5ZsJmrDy+gtLKGA3q0p6q2jhVbyyivrqVzdhr98sPfhe+dORspLq/m+qP3a3Ssps7Nmz9vYP7G3Vx5WF9cSUJeZhqbSyrom5dJRqqL9+YW0icvg27t24W1+59nAyn/56Me/MK7MOO6h06jzm34ee0uxvbLZeOuCq55ZTbPXHYQ+3fOoqK6jsH3fA7AnLtOoFNWWtjXG6l35mxkxdY9/OW0wSEnYm4pqaBrTjo79lTx+qwN/OH4/t5h162RBgWV8Grr3Nz81nxKK2t4/jejSU9puCRHndvgNoZtpZV8OG8T8zYU8/XyHY7n6tY+nS0llc1Wtn+cN4xZa3bx/rxCOmSk8OHvDufYh2d4j//m0D4I8MpPDbcXObRfHos3l1BaWetNu/6ofkxetIXM1GSGdM/hH+cO4++TlzFvQzEPnz+c/TtnUVvn5uynf+TXTSUArPn7OJKSBGMMFTV1ZKQmc9+kxbz847oGn9c5O63RNrEeSx44mRRXEslJQkVNHUkivPTDOvKz00hOEv749nwAThrShQWFu9lWWsWv952EK0m8zXkA/zh3GHXGMPGDX3nwzKGUVtbyz6nLOXtkD647sh8XPz+Tkooab/5F958MQFZaMtW1blKTrVFqizaVMLhbDu/PLWTyoi10zk5jQJdsrjmiABFhZ1kVe6vqGtQ29lbXsmRzKaP75vLFkm1c96p1b/n+jmPJTkuhqLyK7h3akepK4vPFWxGgeG8NYwo6csIj3/LncYOYs66YaUu28c/zhpGdnsIpB3QN+f3X1rmZsmgrpx3YrcUGSWhQUKoJXvlxHcYYdlfU8Nj0lVx7RAFXHNaXDhkpfDBvEz06tGPJllKOGZjP+H/9AFijpE574rsGN8/+nbOoqnXTOTuNXeXVASf3NdVvDu3Dqz+Ftx/VYxeOYM2OMp74apU3rW9eBgO7ZnNw31z++tlSBnfLYemW0ojKcGT/TkEnLkbiuEGd+WrZdlxJQkaqiz0+QS+QB88cyt0fL+baIwr4ZsUOVm4v45iB+cxwCOzXHVnA89+tBeCjGw/HGMPizaX8vHYXkxZs5vs7juXhqcv5aP7miMp9cN+OjfYsuf2UgXwwbxNXHNaXaYu3MqRbDhPHDaaqto6vl23n5KFdeemHdTzw6RL+7/zhnDOqh7fmePXLszn1gK4cO6gzPTtmYIzhpR/WsXtvNft3yWb88O4Rlc+XBgWloswYQ53bkOxKwhjDyz+u4/NFW+nZMYN7zhhC+3Yp3ryVNXVsK62kd24GP6wq4vIXZ5HiSuKxC0fwu9fnAdZ2rHedNph7Pl4c6CMB+Pa2Y72/dvv/ZTI1dc7/h7PTk8O6ufr7v/OH86d3FzRIO2tEdz6av5ljBuZz7xlD+XzRVv7382WN3nvy0C5MtTd56tGhHSJQWOzcp/PExSN5ZNpy1hUFbsbzuO3kgYzq3ZGLn58Z8fX4G92nI3MCNAlCZP1Q4fr3ZQexbGspj00PvMTbUQPy+XZFfUA7fVg3vly6vUET5dQ/HsXArtlNKoMGBaVaOU8b+8fzN/HwtOW8fs1YeudlUF3r5tWf1rFx115e+Wk9++VnctHBvblwTC9y0lManOMfny/j6Rmr+e72Y2mfkcLED35lU3GF3TxVxP99scI72uq4QZ25+vACLnthVsAyPXTOgVw0pn7PkhXb9lDQKZMUV1KD5UmMMUxZtJXeuRnsKq/m3bmFDO2ew4Qj+/GHt36hssbNQ+ceSFZaMj+s2sl/vlvLwxcM56+fLmHDrr28fNUY8rPTqKyp48bX57FyexlXHtaXBz5dQn52GtccUcBDU+qDzqq/nUqyK4n5G3dz1lM/OJZ9WM/2LCwsYWTvDizaVEJNnWH+PSfy7LdreGbGagD2y88MOfR5wb0nsXHXXk5/8nsAzhzRnY/tGsSSB07mya9W8cyM1XTMSGFI9xxG9OrAVYcX8L9TlvHuXOeZ/M3l3jOGcNXhBU16rwYFpdo4YwzbSqvo2j49YJ6aOjc1dW4yUgPvl/X+3EKe+WY1b1x3CJ2zrXO53YZVO8o46dFvSXUlUV3n5srD+nLf+KHNfh2RKKmoISc92dvJW+c2VNXWea/PGMPNb83nmIH5fLZwC0f078SnC7dQU+fm2csP4pa3F/DIhcMBmLd+N6cN6wbAxA8WMqR7exZu3M27cwt5/KIR3PyW1efx/04YwKPTrWXifTuy91bXsmhTKWMKcrnk+ZmUVtbw6e+PpLbOzZuzN3Ly0C7ev09P2QomTgasms3jX66kutbd4PpSXEL/ztlcdXhflmwp5aUf1jX6O3j28oO4/r9zva+XPnAK7VJdzFi+nZG9OzaogUZCg4JSKqTtpZW0S3Xx0JRl/OmkgeRmpsa6SFFVVFbFtCXbuHB0L25+ez5dstO46/QhbCutpEtO4ODrdhtECDkiacW2PWwtqeSoAfmANfQ2Kz2Zf3y+jPzsNCYc1XDUV987PwPgiP07MapPR64/qh+ZacmU7K3hshdmcccpgziif/PMh9GgoJRSrdyyraV8tnALt5w4IOp7kbSGPZqVUkoFMahrDoO65sS6GA3oMpRKKaW8NCgopZTy0qCglFLKS4OCUkopLw0KSimlvDQoKKWU8tKgoJRSykuDglJKKa82N6NZRHYA4a0Z3FgnYGczFqct0GtODHrNiWFfrrmPMSY/VKY2FxT2hYjMCWeadzzRa04Mes2JoSWuWZuPlFJKeWlQUEop5ZVoQeG5WBcgBvSaE4Nec2KI+jUnVJ+CUkqp4BKtpqCUUioIDQpKKaW8EiYoiMgpIrJcRFaJyJ2xLk9zEZFeIvK1iCwVkcUicrOdnisiX4jISvuxo50uIvKE/fewUERGxfYKmkZEXCLyi4h8ar8uEJFZ9vW+LSKpdnqa/XqVfbxvLMvdVCLSQUTeE5Fl9nd9aAJ8x//P/je9SETeFJH0ePyeReRFEdkuIot80iL+bkXkCjv/ShG5oqnlSYigICIu4CngVGAIcLGIDIltqZpNLfAnY8xgYCxwo31tdwJfGmP6A1/ar8H6O+hv/5kAPNPyRW4WNwNLfV7/L/Cofb3FwDV2+jVAsTFmf+BRO19b9DjwuTFmEDAc69rj9jsWkR7AH4DRxpgDABdwEfH5Pb8MnOKXFtF3KyK5wL3AIcAY4F5PIImYMSbu/wCHAlN9Xk8EJsa6XFG61o+BE4HlQDc7rRuw3H7+LHCxT35vvrbyB+hp/0c5DvgUEKxZnsn+3zcwFTjUfp5s55NYX0OE15sDrPUvd5x/xz2AjUCu/b19Cpwcr98z0BdY1NTvFrgYeNYnvUG+SP4kRE2B+n9gHoV2Wlyxq8wjgVlAF2PMFgD7sbOdLR7+Lh4Dbgfc9us8YLcxptZ+7XtN3uu1j5fY+duSfsAO4CW7yYmPXdAAAAPRSURBVOw/IpJJHH/HxphNwMPABmAL1vc2l/j+nn1F+t0223eeKEFBHNLiaiyuiGQB7wN/NMaUBsvqkNZm/i5E5HRguzFmrm+yQ1YTxrG2IhkYBTxjjBkJlFPfnOCkzV+z3fRxJlAAdAcysZpO/MXT9xyOQNfZbNefKEGhEOjl87onsDlGZWl2IpKCFRBeN8Z8YCdvE5Fu9vFuwHY7va3/XRwOjBeRdcBbWE1IjwEdRCTZzuN7Td7rtY+3B3a1ZIGbQSFQaIyZZb9+DytIxOt3DHACsNYYs8MYUwN8ABxGfH/PviL9bpvtO0+UoDAb6G+PXEjF6rCaFOMyNQsREeAFYKkx5hGfQ5MAzwiEK7D6Gjzpv7FHMYwFSjzV1LbAGDPRGNPTGNMX63v8yhhzKfA1cJ6dzf96PX8P59n529QvSGPMVmCjiAy0k44HlhCn37FtAzBWRDLsf+Oea47b79lPpN/tVOAkEelo17JOstMiF+sOlhbsyBkHrABWA3+JdXma8bqOwKomLgTm23/GYbWnfgmstB9z7fyCNRJrNfAr1uiOmF9HE6/9GOBT+3k/4GdgFfAukGanp9uvV9nH+8W63E281hHAHPt7/gjoGO/fMXA/sAxYBPwXSIvH7xl4E6vfpAbrF/81Tflugavt618FXNXU8ugyF0oppbwSpflIKaVUGDQoKKWU8tKgoJRSykuDglJKKS8NCkoppbw0KCjVgkTkGM/Krkq1RhoUlFJKeWlQUMqBiFwmIj+LyHwRedbev6FMRP5PROaJyJcikm/nHSEiM+317T/0Wft+fxGZLiIL7PfsZ58+y2dvhNftGbtKtQoaFJTyIyKDgQuBw40xI4A64FKsRdnmGWNGAd9grV8P8CpwhzFmGNYsU0/668BTxpjhWOv2eJaaGAn8EWtvj35Y6zkp1Sokh86iVMI5HjgImG3/iG+HtSCZG3jbzvMa8IGItAc6GGO+sdNfAd4VkWyghzHmQwBjTCWAfb6fjTGF9uv5WGvpfx/9y1IqNA0KSjUmwCvGmIkNEkXu9ssXbI2YYE1CVT7P69D/h6oV0eYjpRr7EjhPRDqDd7/cPlj/XzwrdF4CfG+MKQGKReRIO/1y4Btj7WlRKCJn2edIE5GMFr0KpZpAf6Eo5ccYs0RE7gKmiUgS1uqVN2JtbjNUROZi7ex1of2WK4B/2zf9NcBVdvrlwLMi8oB9jvNb8DKUahJdJVWpMIlImTEmK9blUCqatPlIKaWUl9YUlFJKeWlNQSmllJcGBaWUUl4aFJRSSnlpUFBKKeWlQUEppZTX/wdDmS0CQYLXXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=256, activation='relu', input_dim=512))\n",
    "model.add(Dropout(0.7))\n",
    "# model.add(Dense(units=128, activation='relu'))\n",
    "# model.add(Dropout(0.7))\n",
    "# model.add(Dense(units=64, activation='relu'))\n",
    "# model.add(Dropout(0.7))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(units=8, activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=3e-4, momentum=0.9)\n",
    "rms = RMSprop(lr=1e-3, rho=0.9)\n",
    "adam = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = adam, metrics = ['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(x_train, y_train, epochs=1000, batch_size=128, verbose=1, validation_data=(x_valid, y_valid))\n",
    "print(history.history.keys())\n",
    "\n",
    "# accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left') \n",
    "plt.show()\n",
    "\n",
    "# loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1378/1378 [==============================] - 0s 18us/step\n",
      "[3.5545830567447125, 0.45428156748911463]\n",
      "acc: 45.43%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x=x_test, y=y_test, batch_size=64, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
