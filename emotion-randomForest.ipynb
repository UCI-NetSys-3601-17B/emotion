{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import data_loader\n",
    "import numpy as np\n",
    "import keras\n",
    "import pickle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from time import time as runtime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images size is:  11086\n",
      "valid_images size is:  1226\n",
      "test_images size is:  1378\n",
      "label_dict size is:  8\n",
      "dict_keys(['neutral', 'sadness', 'contempt', 'surprise', 'disgust', 'anger', 'happiness', 'fear'])\n",
      "y_train: (11086,)\n",
      "y_valid: (1226,)\n"
     ]
    }
   ],
   "source": [
    "img_dir_path = 'origin/images'\n",
    "label_file_path = 'origin/data/legend.csv'\n",
    "valid_rate = 0.1\n",
    "\n",
    "train_file_paths, \\\n",
    "y_train, \\\n",
    "valid_file_paths, \\\n",
    "y_valid, \\\n",
    "test_file_paths, \\\n",
    "y_test, \\\n",
    "label_dict = data_loader.load_dataset(img_dir_path, label_file_path, valid_rate)\n",
    "\n",
    "print('train_images size is: ', len(train_file_paths))\n",
    "print('valid_images size is: ', len(valid_file_paths))\n",
    "print('test_images size is: ', len(test_file_paths))\n",
    "print('label_dict size is: ', len(label_dict))\n",
    "print(label_dict.keys())\n",
    "\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_valid:', y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the extracted features by CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train is (11086, 512)\n",
      "x_valid is (1226, 512)\n",
      "x_test is (1378, 512)\n"
     ]
    }
   ],
   "source": [
    "with open(\"extract/x_train_norm\", \"rb\") as f:\n",
    "    x_train = np.array(pickle.load(f))\n",
    "\n",
    "with open(\"extract/x_valid_norm\", \"rb\") as f:\n",
    "    x_valid = np.array(pickle.load(f))\n",
    "\n",
    "with open(\"extract/x_test_norm\", \"rb\") as f:\n",
    "    x_test = np.array(pickle.load(f))\n",
    "\n",
    "print(\"x_train is\", x_train.shape)\n",
    "print(\"x_valid is\", x_valid.shape)\n",
    "print(\"x_test is\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implement random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy with depth  5  :  0.5038787660111853\n",
      "validation accuracy with depth  5  :  0.5032626427406199\n",
      "test accuracy with depth  5  :  0.4985486211901306\n",
      "training accuracy with depth  10  :  0.905285946238499\n",
      "validation accuracy with depth  10  :  0.5032626427406199\n",
      "test accuracy with depth  10  :  0.5014513788098693\n",
      "training accuracy with depth  15  :  0.9338805700883998\n",
      "validation accuracy with depth  15  :  0.5024469820554649\n",
      "test accuracy with depth  15  :  0.5029027576197388\n",
      "training accuracy with depth  20  :  0.9997293884178243\n",
      "validation accuracy with depth  20  :  0.5008156606851549\n",
      "test accuracy with depth  20  :  0.5058055152394775\n"
     ]
    }
   ],
   "source": [
    "train_rate = []\n",
    "valid_rate = []\n",
    "test_rate = []\n",
    "estimator_number = 1000\n",
    "depth = [5, 10, 15, 20]\n",
    "# process the training data\n",
    "for d in depth:\n",
    "    clf = clf = RandomForestClassifier(n_estimators=estimator_number, max_depth=d, random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    # training data predict\n",
    "    Xtr_pre = clf.predict(x_train)\n",
    "    # validation data predict\n",
    "    Xva_pre = clf.predict(x_valid)\n",
    "    # test data predict\n",
    "    xte_pre = clf.predict(x_test)\n",
    "    \n",
    "    # training data rate\n",
    "    train_count = 0;\n",
    "    for i in range(len(y_train)):\n",
    "        if y_train[i] == Xtr_pre[i]:\n",
    "            train_count += 1\n",
    "    train_rate.append(train_count/len(x_train))\n",
    "    print('training accuracy with depth ',d,' : ',train_count/len(x_train))\n",
    "    \n",
    "    # validation data rate\n",
    "    validation_count = 0;\n",
    "    for i in range(len(y_valid)):\n",
    "        if y_valid[i] == Xva_pre[i]:\n",
    "            validation_count += 1\n",
    "    valid_rate.append(validation_count/len(x_valid))\n",
    "    print('validation accuracy with depth ',d,' : ',validation_count/len(x_valid))\n",
    "    \n",
    "    # test data rate\n",
    "    test_count = 0;\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] == xte_pre[i]:\n",
    "            test_count += 1\n",
    "    test_rate.append(test_count/len(x_test))\n",
    "    print('test accuracy with depth ',d,' : ',test_count/len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
